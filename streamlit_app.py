# -*- coding: utf-8 -*- # Pour assurer la compatibilit√© des caract√®res sp√©ciaux
import streamlit as st
import pandas as pd
from PIL import Image
import io
import base64
import numpy as np
import os
import time # Optional: To demonstrate loading time difference
import traceback # For detailed error reporting
import joblib # <-- AJOUT : Pour charger les mod√®les .joblib
import json   # <-- AJOUT : Pour charger les fichiers .json
import datetime # <-- AJOUT : Pour manipuler les dates
import gdown # <-- AJOUT√â : Pour t√©l√©charger depuis Google Drive

# =============================================================================
# --- 1. CONFIGURATION ---
# =============================================================================

# --- LOCAL FILE PATHS ---
# Les chemins GDrive restent inchang√©s
ECO2MIX_CSV_PATH = 'https://drive.google.com/file/d/1hvEXS7ABSGUh45QHvoR1aCKzJzsQ0S4B/view?usp=drive_link'
SOUTIRAGE_CSV_PATH = 'https://drive.google.com/file/d/1vIsX-TemlEYBTH9dNA4vaEY_6lcYiX6j/view?usp=drive_link'

# <-- MODIFI√â : Chemins relatifs depuis la racine du projet (streamlit_app.py) -->
EFFECTIFS_CSV_PATH = '2. base_etablissement_par_tranche_effectif.csv'
TEMPERATURE_CSV_PATH = '3. temperature-quotidienne-regionale.csv'
POPULATION_CSV_PATH = '4. Population - Insee.csv'
DF_FINAL_CSV_PATH = '6. df_final.csv'
CORRELATION_MATRIX_IMAGE_PATH = 'Visualisation/matrice.png'
MODEL_PREDICTION_IMAGE_PATH = 'Visualisation/modele.png'

# --- AJOUT: CHEMINS DES ARTEFACTS ML ---
# <-- MODIFI√â : Chemin relatif pour le dossier -->
ML_ARTIFACTS_DIR = 'Machine_learning' # Dossier relatif √† streamlit_app.py
BEST_PIPELINE_PATH = os.path.join(ML_ARTIFACTS_DIR, 'best_pipeline_rf.joblib')
COLUMNS_INFO_PATH = os.path.join(ML_ARTIFACTS_DIR, 'columns_info.json')
REGIONS_PATH = os.path.join(ML_ARTIFACTS_DIR, 'regions.json')
# Note: Pas besoin de charger model_rf.joblib et preprocessor.joblib s√©par√©ment
# car best_pipeline_rf.joblib contient d√©j√† le pipeline complet (pr√©processeur + mod√®le)

# --- AJOUT CHEMIN LOGO ---
# <-- MODIFI√â : Chemin relatif -->
LOGO_PATH = 'Visualisation/logo.png' # Chemin relatif √† streamlit_app.py

# --- Section Icons ---
SECTION_ICONS = {
    "üëã Introduction": "üëã Introduction",
    "üîé Exploration des donn√©es": "üîé Exploration des donn√©es",
    "üìä Data Visualisation": "üìä Data Visualisation",
    # "üõ†Ô∏è Preprocessing des Donn√©es üõ†Ô∏è": "üõ†Ô∏è Preprocessing", # Comment√© ou supprim√© si plus dans le menu principal
    "‚öôÔ∏è Mod√©lisation": "‚öôÔ∏è Mod√©lisation",
    "ü§ñ Pr√©diction": "ü§ñ Pr√©diction", # <-- AJOUT√â DANS LE DICTIONNAIRE
    "üìå Conclusion": "üìå Conclusion"
}

# =============================================================================
# --- 2. STREAMLIT APP CONFIGURATION ---
# =============================================================================

st.set_page_config(
    page_title="Consommation d'√âlectricit√© en France",
    page_icon="‚ö°",
    layout="wide"
)
# =============================================================================
# --- 3. SIDEBAR ---
# =============================================================================

import base64
import os
import streamlit as st

with st.sidebar:
    # --- CSS POUR R√âDUIRE LA LARGEUR DE LA SIDEBAR ---
    st.markdown("""
        <style>
            [data-testid="stSidebar"] {
                width: 305px !important;
                min-width: 305px !important;
                max-width: 305px !important;
            }

            .css-18e3th9 {
                margin-left: 305px !important;
            }

            [data-testid="stSidebar"] > div {
                padding: 0.5rem;
            }

            .custom-signature {
                font-size: 0.9rem;
                text-align: center;
                margin-top: 1.5rem;
                line-height: 1.4;
            }

            .about-label {
                font-size: 0.75rem;
                color: #888888;
                text-transform: uppercase;
                letter-spacing: 1px;
                margin-bottom: 0.3rem;
            }
        </style>
    """, unsafe_allow_html=True)

    # --- TITRE ET MENU ---
    st.markdown("<h1 style='color: #5533FF;'>üìö Sommaire</h1>", unsafe_allow_html=True)
    st.markdown("Aller vers üëá")

    sidebar_options = list(SECTION_ICONS.keys())
    if "üõ†Ô∏è Preprocessing des Donn√©es üõ†Ô∏è" in sidebar_options:
        sidebar_options.remove("üõ†Ô∏è Preprocessing des Donn√©es üõ†Ô∏è")

    if 'choix' not in st.session_state:
        st.session_state.choix = sidebar_options[0]

    def update_choice():
        st.session_state.choix = st.session_state.choix_radio

    current_index = 0
    if st.session_state.choix in sidebar_options:
        current_index = sidebar_options.index(st.session_state.choix)
    else:
        st.session_state.choix = sidebar_options[0]

    choix = st.radio(
        "",
        sidebar_options,
        key='choix_radio',
        index=current_index,
        on_change=update_choice,
        format_func=lambda x: SECTION_ICONS.get(x, x)
    )

    # --- S√âPARATEUR ---
    st.markdown("<hr>", unsafe_allow_html=True)

    # --- LOGO ---
    if os.path.exists(LOGO_PATH):
        try:
            with open(LOGO_PATH, "rb") as image_file:
                encoded_logo = base64.b64encode(image_file.read()).decode()

            st.markdown(f"""
                <div style='margin-top: 2rem; text-align: center;'>
                    <img src='data:image/png;base64,{encoded_logo}' style='width:100%; max-width: 200px; margin-bottom: 1rem;'/>
                </div>
            """, unsafe_allow_html=True)

        except Exception as e:
            st.error(f"Erreur chargement logo: {e}")
    else:
        st.warning(f"Logo non trouv√© : {LOGO_PATH}")
        print(f"Warning: Logo file not found at {LOGO_PATH}")

    # --- LIEN VERS LINKEDIN ---
    st.markdown("""
        <div style='text-align: center; margin-top: 1rem;'>
            <a href="https://www.linkedin.com/in/jeremy-vanerpe/" target="_blank" style="text-decoration: none; font-weight: bold; color: #0077B5;">
                üëâ Contactez-moi sur LinkedIn
            </a>
        </div>
    """, unsafe_allow_html=True)

    # --- SIGNATURE / FONCTION ---
    st.markdown("""
        <div class="custom-signature" style="color: #CCCCCC;">
            <div class="about-label">√Ä propos</div>
            <strong style="color: #DDDDDD;">J√©r√©my VAN ERPE</strong><br>
            Optimisation financi√®re,<br>
            Analyse de donn√©es & Conseil
        </div>
    """, unsafe_allow_html=True)



# =============================================================================
# --- NOUVELLE SECTION: FONCTIONS DE CHARGEMENT DES ARTEFACTS ML ---
# =============================================================================


@st.cache_resource # Cache les objets non s√©rialisables comme les mod√®les/pipelines
def load_pipeline(path):
    """Charge le pipeline ML depuis un fichier .joblib."""
    print(f"--- Chargement du pipeline depuis {path} ---")
    try:
        pipeline = joblib.load(path)
        print("--- Pipeline charg√© avec succ√®s. ---")
        return pipeline
    except FileNotFoundError:
        st.error(f"ERREUR : Fichier pipeline introuvable : {path}")
        print(f"Error: Pipeline file not found: {path}")
        return None
    except Exception as e:
        st.error(f"Erreur lors du chargement du pipeline ({path}): {e}")
        print(f"Error loading pipeline ({path}): {e}")
        traceback.print_exc()
        return None

@st.cache_data # Cache les donn√©es s√©rialisables comme les listes/dictionnaires JSON
def load_json_data(path):
    """Charge les donn√©es depuis un fichier JSON."""
    print(f"--- Chargement des donn√©es JSON depuis {path} ---")
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"--- Donn√©es JSON charg√©es depuis {path}. ---")
        return data
    except FileNotFoundError:
        st.error(f"ERREUR : Fichier JSON introuvable : {path}")
        print(f"Error: JSON file not found: {path}")
        return None
    except json.JSONDecodeError:
        st.error(f"ERREUR : Le fichier {path} n'est pas un JSON valide.")
        print(f"Error: File {path} is not valid JSON.")
        return None
    except Exception as e:
        st.error(f"Erreur lors du chargement du JSON ({path}): {e}")
        print(f"Error loading JSON ({path}): {e}")
        traceback.print_exc()
        return None

# --- Chargement effectif des artefacts (appel des fonctions cach√©es) ---
# Sera ex√©cut√© une seule fois gr√¢ce au cache
pipeline = load_pipeline(BEST_PIPELINE_PATH)
columns_info = load_json_data(COLUMNS_INFO_PATH)
regions_list = load_json_data(REGIONS_PATH)


# =============================================================================
# --- 4. INTERNAL DATA LOADING FUNCTIONS (with @st.cache_data) ---
# =============================================================================
# Fonctions internes pr√©fix√©es par _ pour indiquer leur usage priv√©
# Elles contiennent la logique de chargement et de pr√©-traitement de base.

# /!\ MODIFICATION CI-DESSOUS POUR GOOGLE DRIVE /!\
@st.cache_data
def _load_eco2mix_internal(file_identifier):
    """Charge et pr√©pare les donn√©es Eco2mix. G√®re les URL GDrive ou les chemins locaux. Mis en cache."""
    print(f"--- Executing _load_eco2mix_internal for identifier: {file_identifier} ---")
    local_path_to_read = None
    temp_file_downloaded = False

    # D√©tecter si c'est une URL Google Drive
    if isinstance(file_identifier, str) and file_identifier.startswith('https://drive.google.com/'):
        # D√©finir un chemin de destination temporaire pour le t√©l√©chargement
        temp_eco2mix_path = '/tmp/eco2mix_temp_download.csv' # Utilise /tmp qui est g√©n√©ralement disponible
        print(f"--- Identifier is a Google Drive URL. Attempting download to {temp_eco2mix_path}... ---")
        try:
            # Supprimer l'ancien fichier temporaire s'il existe
            if os.path.exists(temp_eco2mix_path):
                os.remove(temp_eco2mix_path)
                print(f"--- Removed existing temp file: {temp_eco2mix_path} ---")

            # T√©l√©charger le fichier depuis Google Drive
            gdown.download(url=file_identifier, output=temp_eco2mix_path, quiet=False, fuzzy=True) # fuzzy=True aide avec les gros fichiers
            print(f"--- Google Drive file downloaded successfully to {temp_eco2mix_path} ---")
            local_path_to_read = temp_eco2mix_path
            temp_file_downloaded = True # Marquer qu'un fichier temporaire a √©t√© cr√©√©

        except Exception as e_gdown:
            st.error(f"Erreur lors du t√©l√©chargement depuis Google Drive ({file_identifier}): {e_gdown}")
            print(f"Error: Failed to download from Google Drive URL {file_identifier}: {e_gdown}")
            traceback.print_exc()
            return None # √âchec du chargement
    else:
        # Si ce n'est pas une URL GDrive, on suppose que c'est un chemin local
        print(f"--- Identifier is treated as a local path: {file_identifier} ---")
        if not os.path.exists(file_identifier):
             print(f"Error: Local file not found: {file_identifier}")
             st.error(f"Fichier local non trouv√©: {file_identifier}") # Remettre l'erreur si chemin local
             return None
        local_path_to_read = file_identifier # Utiliser le chemin local directement

    # V√©rifier si un chemin de lecture a √©t√© d√©fini
    if local_path_to_read is None:
        print("Error: No valid local path determined for reading.")
        st.error("Impossible de d√©terminer le fichier √† lire (probl√®me de t√©l√©chargement ou chemin local invalide).")
        return None

    # --- Logique de lecture Pandas (inchang√©e, mais utilise local_path_to_read) ---
    df = None
    try:
        # Essai avec ; et utf-8
        df = pd.read_csv(local_path_to_read, sep=';', encoding='utf-8')
        print(f"--- Eco2mix loaded from '{local_path_to_read}' with sep=';', encoding='utf-8'.")
    except (UnicodeDecodeError, pd.errors.ParserError):
        print(f"Warning: Failed reading Eco2mix from '{local_path_to_read}' with semicolon/utf-8. Trying semicolon/latin-1...")
        try:
            df = pd.read_csv(local_path_to_read, sep=';', encoding='latin-1')
            print(f"--- Eco2mix loaded from '{local_path_to_read}' with sep=';', encoding='latin-1'.")
        except (UnicodeDecodeError, pd.errors.ParserError):
            print(f"Warning: Failed reading Eco2mix from '{local_path_to_read}' with semicolon/latin-1. Trying comma/utf-8...")
            try:
                df = pd.read_csv(local_path_to_read, sep=',', encoding='utf-8')
                print(f"--- Eco2mix loaded from '{local_path_to_read}' with sep=',', encoding='utf-8'.")
            except (UnicodeDecodeError, pd.errors.ParserError):
                print(f"Warning: Failed reading Eco2mix from '{local_path_to_read}' with comma/utf-8. Trying comma/latin-1...")
                try:
                    df = pd.read_csv(local_path_to_read, sep=',', encoding='latin-1')
                    print(f"--- Eco2mix loaded from '{local_path_to_read}' with sep=',', encoding='latin-1'.")
                except Exception as final_e:
                    print(f"Error: Final read error for Eco2mix from '{local_path_to_read}': {final_e}")
                    st.error(f"Erreur finale de lecture Eco2mix {local_path_to_read}: {final_e}")
                    traceback.print_exc()
                    return None
            except Exception as e_comma:
                 print(f"Error: Read error for Eco2mix from '{local_path_to_read}' with sep=',': {e_comma}")
                 st.error(f"Erreur de lecture Eco2mix {local_path_to_read} avec sep=',': {e_comma}")
                 traceback.print_exc()
                 return None
        except Exception as e_semicolon:
            print(f"Error: Read error for Eco2mix from '{local_path_to_read}' with sep=';': {e_semicolon}")
            st.error(f"Erreur de lecture Eco2mix {local_path_to_read} avec sep=';': {e_semicolon}")
            traceback.print_exc()
            return None
    except pd.errors.EmptyDataError:
         print(f"Warning: Eco2mix file {local_path_to_read} is empty.")
         st.warning(f"Le fichier Eco2mix {local_path_to_read} est vide.")
         df = pd.DataFrame() # Retourner un DF vide
    except FileNotFoundError: # Au cas o√π le fichier temp dispara√Ætrait entre le t√©l√©chargement et la lecture
        print(f"ERROR: File {local_path_to_read} not found unexpectedly.")
        st.error(f"ERREUR: Fichier non trouv√© de mani√®re inattendue √† {local_path_to_read}")
        return None
    except Exception as e:
         print(f"Error: Unexpected error loading Eco2mix from '{local_path_to_read}': {e}")
         st.error(f"Erreur inattendue lors du chargement Eco2mix ({local_path_to_read}): {e}")
         traceback.print_exc()
         return None

    # Nettoyage du fichier temporaire SI il a √©t√© t√©l√©charg√©
    # if temp_file_downloaded and os.path.exists(local_path_to_read):
    #     try:
    #         os.remove(local_path_to_read)
    #         print(f"--- Cleaned up temporary file: {local_path_to_read} ---")
    #     except Exception as e_clean:
    #         print(f"Warning: Could not clean up temporary file {local_path_to_read}: {e_clean}")

    if df is None and not isinstance(df, pd.DataFrame): # Si aucune m√©thode n'a fonctionn√© mais pas d'exception fatale ET pas de DF vide retourn√©
        print(f"Error: Cannot read Eco2mix file {local_path_to_read} with tested separators/encodings.")
        st.error(f"Impossible de lire le fichier Eco2mix {local_path_to_read} avec les s√©parateurs/encodages test√©s.")
        return None

    # Pr√©traitement de base (inchang√©)
    if not df.empty:
        df = df.replace('ND', np.nan)
        if 'Date' in df.columns:
             df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        if 'Consommation (MW)' in df.columns:
             df['Consommation (MW)'] = pd.to_numeric(df['Consommation (MW)'], errors='coerce')

    print(f"--- Eco2mix preprocessed. Shape: {df.shape} ---")
    return df
# /!\ FIN MODIFICATION ECO2MIX /!\


@st.cache_data
def _load_effectifs_internal(file_path):
    """Charge et pr√©pare les donn√©es Effectifs. Mis en cache."""
    # st.toast(f"‚è≥ Chargement Effectifs depuis {file_path}...") # Moins de toasts
    print(f"--- Executing _load_effectifs_internal for {file_path} ---")
    if not os.path.exists(file_path):
        # st.error(f"Fichier Effectifs non trouv√©: {file_path}") # Moins d'erreurs directes
        print(f"Error: Effectifs file not found: {file_path}")
        return None
    df = None
    try:
        # Essayer le s√©parateur virgule en premier
        df = pd.read_csv(file_path, sep=',', encoding='utf-8')
        print("--- Effectifs loaded successfully with sep=',' and encoding='utf-8'.")
    except (UnicodeDecodeError, pd.errors.ParserError):
        print(f"Warning: Failed reading Effectifs with comma/utf-8. Trying comma/latin-1...")
        try:
            df = pd.read_csv(file_path, sep=',', encoding='latin-1')
            print("--- Effectifs loaded successfully with sep=',' and encoding='latin-1'.")
        except (UnicodeDecodeError, pd.errors.ParserError):
            print(f"Warning: Failed reading Effectifs with comma/latin-1. Trying semicolon/utf-8...")
            # st.warning(f"√âchec lecture Effectifs avec sep=','. Essai avec sep=';'...") # Moins de warnings directs
            try:
                df = pd.read_csv(file_path, sep=';', encoding='utf-8')
                print("--- Effectifs loaded successfully with sep=';' and encoding='utf-8'.")
            except (UnicodeDecodeError, pd.errors.ParserError):
                print(f"Warning: Failed reading Effectifs with semicolon/utf-8. Trying semicolon/latin-1...")
                try:
                    df = pd.read_csv(file_path, sep=';', encoding='latin-1')
                    print("--- Effectifs loaded successfully with sep=';' and encoding='latin-1'.")
                except Exception as final_e:
                    # st.error(f"Erreur finale de lecture Effectifs {file_path}: {final_e}")
                    print(f"Error: Final read error for Effectifs {file_path}: {final_e}")
                    traceback.print_exc()
                    return None
            except Exception as e_semi:
                 # st.error(f"Erreur de lecture Effectifs {file_path} avec sep=';': {e_semi}")
                 print(f"Error: Read error for Effectifs {file_path} with sep=';': {e_semi}")
                 traceback.print_exc()
                 return None
        except Exception as e_comma:
            # st.error(f"Erreur de lecture Effectifs {file_path} avec sep=',': {e_comma}")
            print(f"Error: Read error for Effectifs {file_path} with sep=',': {e_comma}")
            traceback.print_exc()
            return None
    except pd.errors.EmptyDataError:
        # st.warning(f"Le fichier Effectifs {file_path} est vide.")
        print(f"Warning: Effectifs file {file_path} is empty.")
        return pd.DataFrame()
    except FileNotFoundError:
        # st.error(f"ERREUR: Fichier Effectifs non trouv√© √† {file_path}")
        print(f"ERROR: Effectifs file not found at {file_path}")
        return None
    except Exception as e:
        # st.error(f"Erreur inattendue lors du chargement Effectifs ({file_path}): {e}")
        print(f"Error: Unexpected error loading Effectifs ({file_path}): {e}")
        traceback.print_exc()
        return None

    if df is None:
         # st.error(f"Impossible de lire le fichier Effectifs {file_path} avec les s√©parateurs/encodages test√©s.")
         print(f"Error: Cannot read Effectifs file {file_path} with tested separators/encodings.")
         return None

    if df.empty:
         # st.warning(f"Le fichier Effectifs {file_path} est vide ou n'a pas pu √™tre charg√© correctement.")
         print(f"Warning: Effectifs file {file_path} is empty or could not be loaded correctly.")
         return df # Retourne le DF vide

    # Pr√©traitement : Conversion des colonnes num√©riques
    num_cols = ['E14TST', 'E14TS0ND', 'E14TS1', 'E14TS6', 'E14TS10',
                'E14TS20', 'E14TS50', 'E14TS100', 'E14TS200', 'E14TS500']
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            # Remplacer les NaN par 0 APRES conversion si c'est le comportement souhait√©
            # df[col] = df[col].fillna(0)
            print(f"--- Effectifs: Column '{col}' converted to numeric.")
        else:
            # st.warning(f"Colonne num√©rique attendue '{col}' manquante dans Effectifs.")
            print(f"Warning: Expected numeric column '{col}' missing in Effectifs.")
            # Optionnel: Cr√©er la colonne avec 0 si elle manque et que c'est pertinent
            # df[col] = 0

    # S'assurer que les codes g√©o sont des cha√Ænes de caract√®res format√©es correctement
    for col in ['CODGEO', 'REG', 'DEP']:
         if col in df.columns:
             print(f"--- Effectifs: Processing geo column '{col}'...")
             # 1. V√©rifier si la colonne n'est PAS d√©j√† de type string/object
             if not pd.api.types.is_string_dtype(df[col]):
                 print(f"--- Effectifs: Column '{col}' is not string, attempting conversion.")
                 try:
                    # Convertir en string de mani√®re robuste, g√©rant NaN et types num√©riques
                    # fillna(-1) puis replace('-1', NA) est une astuce pour g√©rer les NaN pendant la conversion int->str
                    df[col] = df[col].fillna(-1).astype(int).astype(str).replace('-1', pd.NA)
                    print(f"--- Effectifs: Column '{col}' converted via int -> str.")
                 except ValueError: # Si contient des strings non num√©riques, convertir simplement en str
                    print(f"--- Effectifs: Column '{col}' conversion via int failed (likely mixed types), converting directly to str.")
                    df[col] = df[col].astype(str)
                 except Exception as e_conv:
                    # st.error(f"Erreur de conversion en string pour la colonne '{col}' dans Effectifs: {e_conv}")
                    print(f"Error: String conversion error for column '{col}' in Effectifs: {e_conv}")
                    # En cas d'√©chec grave, on peut arr√™ter ou continuer avec la colonne potentiellement probl√©matique
                    # return None # Optionnel: arr√™ter si la colonne est critique

             # 2. Nettoyer les '.0' potentiels si la lecture initiale √©tait float
             # S'assurer que c'est bien une string avant d'utiliser .str
             if pd.api.types.is_string_dtype(df[col]):
                 df[col] = df[col].str.replace(r'\.0$', '', regex=True)
             else: # Si ce n'est toujours pas une string apr√®s les tentatives de conversion
                  df[col] = df[col].astype(str).str.replace(r'\.0$', '', regex=True)


             # 3. Appliquer zfill pour les z√©ros non significatifs (uniquement sur les valeurs valides)
             zfill_len = 0
             if col in ['REG', 'DEP']:
                 zfill_len = 2
             elif col == 'CODGEO':
                 zfill_len = 5

             if zfill_len > 0:
                # Assurer que c'est string avant apply
                if not pd.api.types.is_string_dtype(df[col]):
                    df[col] = df[col].astype(str) # Derni√®re tentative de conversion str

                # G√©rer les <NA> ou 'nan' stringifi√©s avant zfill
                df[col] = df[col].apply(
                    lambda x: x.zfill(zfill_len) if pd.notna(x) and x not in ['<NA>', 'nan', 'None'] else x
                )
                print(f"--- Effectifs: Column '{col}' zero-padded to {zfill_len} digits.")
         else:
              # st.warning(f"Colonne g√©ographique attendue '{col}' manquante dans Effectifs.")
              print(f"Warning: Expected geo column '{col}' missing in Effectifs.")


    print(f"--- Effectifs data preprocessed. Shape: {df.shape} ---")
    # print("--- Effectifs dtypes after processing:\n", df.dtypes) # Pour d√©bogage
    # print("--- Effectifs head after processing:\n", df.head()) # Pour d√©bogage
    return df


# /!\ MODIFICATION CI-DESSOUS POUR GOOGLE DRIVE /!\
@st.cache_data
def _load_soutirage_internal(file_identifier):
    """Charge les donn√©es Soutirage. G√®re les URL GDrive ou les chemins locaux. Mis en cache."""
    print(f"--- Executing _load_soutirage_internal for identifier: {file_identifier} ---")
    local_path_to_read = None
    temp_file_downloaded = False

    # D√©tecter si c'est une URL Google Drive
    if isinstance(file_identifier, str) and file_identifier.startswith('https://drive.google.com/'):
        # D√©finir un chemin de destination temporaire pour le t√©l√©chargement
        temp_soutirage_path = '/tmp/soutirage_temp_download.csv' # Utilise /tmp
        print(f"--- Identifier is a Google Drive URL. Attempting download to {temp_soutirage_path}... ---")
        try:
            # Supprimer l'ancien fichier temporaire s'il existe
            if os.path.exists(temp_soutirage_path):
                os.remove(temp_soutirage_path)
                print(f"--- Removed existing temp file: {temp_soutirage_path} ---")

            # T√©l√©charger le fichier depuis Google Drive
            gdown.download(url=file_identifier, output=temp_soutirage_path, quiet=False, fuzzy=True) # fuzzy=True aide
            print(f"--- Google Drive file downloaded successfully to {temp_soutirage_path} ---")
            local_path_to_read = temp_soutirage_path
            temp_file_downloaded = True

        except Exception as e_gdown:
            st.error(f"Erreur lors du t√©l√©chargement depuis Google Drive ({file_identifier}): {e_gdown}")
            print(f"Error: Failed to download from Google Drive URL {file_identifier}: {e_gdown}")
            traceback.print_exc()
            return None
    else:
        # Si ce n'est pas une URL GDrive, on suppose que c'est un chemin local
        print(f"--- Identifier is treated as a local path: {file_identifier} ---")
        if not os.path.exists(file_identifier):
             print(f"Error: Local file not found: {file_identifier}")
             st.error(f"Fichier local non trouv√©: {file_identifier}")
             return None
        local_path_to_read = file_identifier

    # V√©rifier si un chemin de lecture a √©t√© d√©fini
    if local_path_to_read is None:
        print("Error: No valid local path determined for reading.")
        st.error("Impossible de d√©terminer le fichier √† lire (probl√®me de t√©l√©chargement ou chemin local invalide).")
        return None

    # --- Logique de lecture Pandas (inchang√©e, mais utilise local_path_to_read) ---
    df = None
    try:
        df = pd.read_csv(local_path_to_read, sep=';', encoding='utf-8')
        print(f"--- Soutirage loaded from '{local_path_to_read}' with sep=';', encoding='utf-8'.")
    except (UnicodeDecodeError, pd.errors.ParserError):
        print(f"Warning: Failed reading Soutirage from '{local_path_to_read}' with semicolon/utf-8. Trying semicolon/latin-1...")
        try:
             df = pd.read_csv(local_path_to_read, sep=';', encoding='latin-1')
             print(f"--- Soutirage loaded from '{local_path_to_read}' with sep=';', encoding='latin-1'.")
        except (UnicodeDecodeError, pd.errors.ParserError):
             print(f"Warning: Failed reading Soutirage from '{local_path_to_read}' with semicolon/latin-1. Trying comma/utf-8...")
             try:
                 df = pd.read_csv(local_path_to_read, sep=',', encoding='utf-8')
                 print(f"--- Soutirage loaded from '{local_path_to_read}' with sep=',', encoding='utf-8'.")
             except (UnicodeDecodeError, pd.errors.ParserError):
                print(f"Warning: Failed reading Soutirage from '{local_path_to_read}' with comma/utf-8. Trying comma/latin-1...")
                try:
                    df = pd.read_csv(local_path_to_read, sep=',', encoding='latin-1')
                    print(f"--- Soutirage loaded from '{local_path_to_read}' with sep=',', encoding='latin-1'.")
                except Exception as final_e:
                    print(f"Error: Final read error for Soutirage from '{local_path_to_read}': {final_e}")
                    st.error(f"Erreur finale de lecture Soutirage {local_path_to_read}: {final_e}")
                    traceback.print_exc()
                    return None
             except Exception as e_comma:
                 print(f"Error: Read error for Soutirage from '{local_path_to_read}' with sep=',': {e_comma}")
                 st.error(f"Erreur de lecture Soutirage {local_path_to_read} avec sep=',': {e_comma}")
                 traceback.print_exc()
                 return None
        except Exception as e_semicolon:
            print(f"Error: Read error for Soutirage from '{local_path_to_read}' with sep=';': {e_semicolon}")
            st.error(f"Erreur de lecture Soutirage {local_path_to_read} avec sep=';': {e_semicolon}")
            traceback.print_exc()
            return None
    except pd.errors.EmptyDataError:
         print(f"Warning: Soutirage file {local_path_to_read} is empty.")
         st.warning(f"Le fichier Soutirage {local_path_to_read} est vide.")
         df = pd.DataFrame()
    except FileNotFoundError:
        print(f"ERROR: File {local_path_to_read} not found unexpectedly.")
        st.error(f"ERREUR: Fichier non trouv√© de mani√®re inattendue √† {local_path_to_read}")
        return None
    except Exception as e:
         print(f"Error: Unexpected error loading Soutirage from '{local_path_to_read}': {e}")
         st.error(f"Erreur inattendue lors du chargement Soutirage ({local_path_to_read}): {e}")
         traceback.print_exc()
         return None

    # Nettoyage du fichier temporaire SI il a √©t√© t√©l√©charg√©
    # if temp_file_downloaded and os.path.exists(local_path_to_read):
    #     try:
    #         os.remove(local_path_to_read)
    #         print(f"--- Cleaned up temporary file: {local_path_to_read} ---")
    #     except Exception as e_clean:
    #         print(f"Warning: Could not clean up temporary file {local_path_to_read}: {e_clean}")

    if df is None and not isinstance(df, pd.DataFrame):
        print(f"Error: Cannot read Soutirage file {local_path_to_read} with tested separators/encodings.")
        st.error(f"Impossible de lire le fichier Soutirage {local_path_to_read} avec les s√©parateurs/encodages test√©s.")
        return None

    # Ajouter ici un pr√©-traitement sp√©cifique si n√©cessaire (dates, num√©riques...)
    # if not df.empty:
    #    Exemple:
    #    if 'Date' in df.columns:
    #        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    #    if 'Soutirage (MW)' in df.columns: # Adapter le nom de colonne
    #        df['Soutirage (MW)'] = pd.to_numeric(df['Soutirage (MW)'], errors='coerce')

    print(f"--- Soutirage loaded/processed. Shape: {df.shape} ---")
    return df
# /!\ FIN MODIFICATION SOUTIRAGE /!\

@st.cache_data
def _load_temperature_internal(file_path):
    """Charge et pr√©pare les donn√©es Temp√©rature. Mis en cache."""
    # st.toast(f"‚è≥ Chargement Temp√©rature depuis {file_path}...") # Moins de toasts
    print(f"--- Executing _load_temperature_internal for {file_path} ---")
    if not os.path.exists(file_path):
        # st.error(f"Fichier Temp√©rature non trouv√©: {file_path}")
        print(f"Error: Temperature file not found: {file_path}")
        return None
    df = None
    try:
        df = pd.read_csv(file_path, sep=';', encoding='utf-8')
        print("--- Temperature loaded successfully with sep=';' and encoding='utf-8'.")
    except (UnicodeDecodeError, pd.errors.ParserError):
        print("Warning: Failed reading Temperature with semicolon/utf-8. Trying semicolon/latin-1...")
        try:
            df = pd.read_csv(file_path, sep=';', encoding='latin-1')
            print("--- Temperature loaded successfully with sep=';' and encoding='latin-1'.")
        except (UnicodeDecodeError, pd.errors.ParserError):
            print("Warning: Failed reading Temperature with semicolon/latin-1. Trying comma/utf-8...")
            # st.warning(f"√âchec lecture Temp√©rature avec sep=';'. Essai avec sep=','...")
            try:
                df = pd.read_csv(file_path, sep=',', encoding='utf-8')
                print("--- Temperature loaded successfully with sep=',', encoding='utf-8'.")
            except (UnicodeDecodeError, pd.errors.ParserError):
                print("Warning: Failed reading Temperature with comma/utf-8. Trying comma/latin-1...")
                try:
                    df = pd.read_csv(file_path, sep=',', encoding='latin-1')
                    print("--- Temperature loaded successfully with sep=',', encoding='latin-1'.")
                except Exception as final_e:
                    # st.error(f"Erreur finale de lecture Temp√©rature {file_path}: {final_e}")
                    print(f"Error: Final read error for Temperature {file_path}: {final_e}")
                    traceback.print_exc()
                    return None
            except Exception as e_comma:
                 # st.error(f"Erreur de lecture Temp√©rature {file_path} avec sep=',': {e_comma}")
                 print(f"Error: Read error for Temperature {file_path} with sep=',': {e_comma}")
                 traceback.print_exc()
                 return None
        except Exception as e_semicolon:
            # st.error(f"Erreur de lecture Temp√©rature {file_path} avec sep=';': {e_semicolon}")
            print(f"Error: Read error for Temperature {file_path} with sep=';': {e_semicolon}")
            traceback.print_exc()
            return None
    except pd.errors.EmptyDataError:
        # st.warning(f"Le fichier Temp√©rature {file_path} est vide.")
        print(f"Warning: Temperature file {file_path} is empty.")
        return pd.DataFrame()
    except FileNotFoundError:
        # st.error(f"ERREUR: Fichier Temp√©rature non trouv√© √† {file_path}")
        print(f"ERROR: Temperature file not found at {file_path}")
        return None
    except Exception as e:
        # st.error(f"Erreur inattendue lors du chargement Temp√©rature ({file_path}): {e}")
        print(f"Error: Unexpected error loading Temperature ({file_path}): {e}")
        traceback.print_exc()
        return None

    if df is None:
        # st.error(f"Impossible de lire le fichier Temp√©rature {file_path} avec les s√©parateurs/encodages test√©s.")
        print(f"Error: Cannot read Temperature file {file_path} with tested separators/encodings.")
        return None

    if df.empty:
        # st.warning(f"Le fichier Temp√©rature {file_path} est vide apr√®s lecture.")
        print(f"Warning: Temperature file {file_path} is empty after read.")
        return df

    # --- Preprocessing ---
    if 'Date' in df.columns:
        # Essayer plusieurs formats ou laisser pandas d√©duire, puis v√©rifier
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True) # dayfirst=True aide pour formats DD/MM/YYYY
        # Supprimer les lignes o√π la date est invalide (NaT)
        initial_rows = len(df)
        df.dropna(subset=['Date'], inplace=True)
        if len(df) < initial_rows:
             print(f"--- Temperature: Removed {initial_rows - len(df)} rows with invalid dates.")
        if df.empty:
            # st.error("Aucune date valide trouv√©e dans le fichier Temp√©rature apr√®s conversion.")
            print("Error: No valid dates found in Temperature file after conversion.")
            return pd.DataFrame()
        print("--- Temperature: 'Date' column converted to datetime.")
    else:
        # st.error("Colonne 'Date' manquante dans le fichier Temp√©rature.")
        print("Error: 'Date' column missing in Temperature file.")
        return pd.DataFrame() # Retourner DF vide car la date est essentielle

    temp_cols = ['TMin (¬∞C)', 'TMax (¬∞C)', 'TMoy (¬∞C)']
    for col in temp_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            print(f"--- Temperature: Column '{col}' converted to numeric.")
        else:
            # st.warning(f"Colonne de temp√©rature attendue '{col}' manquante.")
            print(f"Warning: Expected temperature column '{col}' missing.")

    if 'R√©gion' not in df.columns:
        # st.error("Colonne 'R√©gion' manquante, n√©cessaire pour le filtrage et l'analyse.")
        print("Error: 'R√©gion' column missing, required for filtering and analysis.")
        # Selon l'importance, retourner None ou un DF vide
        return pd.DataFrame()

    print(f"--- Temperature data preprocessed. Shape: {df.shape} ---")
    return df


@st.cache_data
def _load_population_internal(file_path):
    """Charge et transforme les donn√©es Population. Mis en cache."""
    # st.toast(f"‚è≥ Chargement Population depuis {file_path}...") # Moins de toasts
    print(f"--- Executing _load_population_internal for {file_path} ---")
    if not os.path.exists(file_path):
         # st.error(f"Fichier Population non trouv√©: {file_path}")
         print(f"Error: Population file not found: {file_path}")
         return None
    df = None
    try:
        # Tenter lecture avec virgule d'abord
        df = pd.read_csv(file_path, sep=',', encoding='utf-8')
        print("--- Population loaded with sep=',' and encoding='utf-8'.")
    except (UnicodeDecodeError, pd.errors.ParserError):
        print("Warning: Failed reading Population with comma/utf-8. Trying comma/latin-1...")
        try:
            df = pd.read_csv(file_path, sep=',', encoding='latin-1')
            print("--- Population loaded with sep=',' and encoding='latin-1'.")
        except (UnicodeDecodeError, pd.errors.ParserError):
            print("Warning: Failed reading Population with comma/latin-1. Trying semicolon/utf-8...")
            # st.warning(f"√âchec lecture Population avec sep=',': Essai avec sep=';'.")
            try:
                df = pd.read_csv(file_path, sep=';', encoding='utf-8')
                print("--- Population loaded with sep=';' and encoding='utf-8'.")
            except (UnicodeDecodeError, pd.errors.ParserError):
                 print("Warning: Failed reading Population with semicolon/utf-8. Trying semicolon/latin-1...")
                 try:
                    df = pd.read_csv(file_path, sep=';', encoding='latin-1')
                    print("--- Population loaded with sep=';' and encoding='latin-1'.")
                 except Exception as final_e:
                     # st.error(f"√âchec final lecture Population {file_path}: {final_e}")
                     print(f"Error: Final read error for Population {file_path}: {final_e}")
                     traceback.print_exc()
                     return None
            except Exception as e_semi:
                 # st.error(f"Erreur lecture Population {file_path} avec sep=';': {e_semi}")
                 print(f"Error: Read error for Population {file_path} with sep=';': {e_semi}")
                 traceback.print_exc()
                 return None
        except Exception as e_comma:
            # st.error(f"Erreur lecture Population {file_path} avec sep=',': {e_comma}")
            print(f"Error: Read error for Population {file_path} with sep=',': {e_comma}")
            traceback.print_exc()
            return None
    except pd.errors.EmptyDataError:
         # st.warning(f"Le fichier Population {file_path} est vide.")
         print(f"Warning: Population file {file_path} is empty.")
         return pd.DataFrame()
    except FileNotFoundError:
        # st.error(f"ERREUR: Fichier Population non trouv√© √† {file_path}")
        print(f"ERROR: Population file not found at {file_path}")
        return None
    except Exception as e:
        # st.error(f"Erreur inattendue chargement Population ({file_path}): {e}")
        print(f"Error: Unexpected error loading Population ({file_path}): {e}")
        traceback.print_exc()
        return None

    if df is None:
         # st.error(f"Impossible de lire le fichier Population {file_path} avec les s√©parateurs/encodages test√©s.")
         print(f"Error: Cannot read Population file {file_path} with tested separators/encodings.")
         return None

    if df.empty:
         # st.warning(f"Fichier Population {file_path} vide apr√®s lecture.")
         print(f"Warning: Population file {file_path} empty after read.")
         return df

    # --- Gestion de la colonne Date ---
    date_col_found = False
    if 'Date' in df.columns:
        print("--- Population: 'Date' column found.")
        date_col_found = True
    else:
        # Essayer si la premi√®re colonne est une date
        first_col_name = df.columns[0]
        print(f"--- Population: No 'Date' column. Checking first column '{first_col_name}'...")
        try:
            # Essayer de convertir sans modifier le df pour juste v√©rifier
            pd.to_datetime(df[first_col_name], errors='raise', dayfirst=True)
            df.rename(columns={first_col_name: 'Date'}, inplace=True)
            print(f"--- Population: Renamed first column '{first_col_name}' to 'Date'.")
            date_col_found = True
        except (ValueError, TypeError, KeyError, IndexError):
            # st.error("La colonne 'Date' est manquante et la premi√®re colonne ne semble pas contenir de dates valides.")
            print("Error: 'Date' column missing and first column does not appear to contain valid dates.")
            traceback.print_exc()
            return pd.DataFrame() # Date est essentielle

    if not date_col_found or 'Date' not in df.columns:
         # st.error("Erreur critique : Impossible d'identifier ou de cr√©er la colonne 'Date'.")
         print("Critical Error: Cannot identify or create 'Date' column.")
         return pd.DataFrame()

    # --- Conversion de la colonne Date ---
    try:
        # Essayer format DD/MM/YYYY explicitement
        df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='raise')
        print("--- Population: Date parsed with format %d/%m/%Y.")
    except ValueError:
        print("Warning: Parsing with %d/%m/%Y failed. Trying %Y-%m-%d...")
        try:
             # Essayer format YYYY-MM-DD explicitement
             df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='raise')
             print("--- Population: Date parsed with format %Y-%m-%d.")
        except ValueError:
            print("Warning: Specific date formats failed. Using generic parser with dayfirst=True...")
            # Tentative plus g√©n√©rale, utile pour DD/MM/YY ou autres variations
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True)
            print("--- Population: Date parsed with generic parser.")

    # Supprimer les lignes o√π la date n'a pas pu √™tre convertie
    initial_rows_pop = len(df)
    df.dropna(subset=['Date'], inplace=True)
    if len(df) < initial_rows_pop:
         print(f"--- Population: Removed {initial_rows_pop - len(df)} rows with invalid dates after conversion attempts.")
    if df.empty:
         # st.error("Aucune date valide trouv√©e apr√®s conversion dans le fichier Population.")
         print("Error: No valid dates found after conversion in Population file.")
         return pd.DataFrame()

    # --- Transformation Wide to Long (Melt) ---
    region_cols = [col for col in df.columns if col != 'Date']
    if not region_cols:
         # st.error("Aucune colonne de r√©gion/valeur trouv√©e pour la transformation (melt).")
         print("Error: No region/value columns found for melt transformation.")
         return pd.DataFrame()

    try:
        df_long = pd.melt(df, id_vars=['Date'], value_vars=region_cols,
                          var_name='R√©gion', value_name='Population_raw')
        print(f"--- Population data reshaped (melted). Shape: {df_long.shape} ---")
    except Exception as e_melt:
        # st.error(f"Erreur lors du 'melt' (transformation format long) pour Population: {e_melt}")
        print(f"Error during melt (long format transformation) for Population: {e_melt}")
        traceback.print_exc()
        return None # Erreur critique

    # --- Nettoyage et Conversion des valeurs de Population ---
    if 'Population_raw' in df_long.columns:
         # 1. Convertir en string, nettoyer espaces et remplacer virgule d√©cimale par point
         df_long['Population_cleaned'] = df_long['Population_raw'].astype(str).str.replace(' ', '', regex=False).str.replace(',', '.', regex=False)
         # 2. Convertir en num√©rique, les erreurs deviennent NaN
         df_long['Population'] = pd.to_numeric(df_long['Population_cleaned'], errors='coerce')
         # 3. Supprimer les lignes o√π la population est invalide (NaN)
         initial_rows_long = len(df_long)
         df_long.dropna(subset=['Population'], inplace=True)
         if len(df_long) < initial_rows_long:
              print(f"--- Population: Removed {initial_rows_long - len(df_long)} rows with invalid population values.")
    else:
        # st.error("Colonne 'Population_raw' non cr√©√©e par melt. Impossible de traiter les valeurs.")
        print("Error: 'Population_raw' column not created by melt. Cannot process values.")
        return pd.DataFrame()

    if df_long.empty:
        # st.error("DataFrame Population vide apr√®s conversion/nettoyage des valeurs de population.")
        print("Error: Population DataFrame empty after converting/cleaning population values.")
        return pd.DataFrame()

    # 4. Convertir en entier (si appropri√© pour la population)
    try:
        df_long['Population'] = df_long['Population'].astype(int)
    except ValueError:
        # st.warning("Impossible de convertir toutes les valeurs de Population en entier. Elles resteront en flottant.")
        print("Warning: Cannot convert all Population values to integer. They will remain float.")
        # Garder en float si la conversion √©choue
        pass

    # 5. Supprimer les colonnes interm√©diaires
    df_long.drop(columns=['Population_raw', 'Population_cleaned'], inplace=True, errors='ignore')

    print(f"--- Population data fully processed (long format). Final Shape: {df_long.shape} ---")
    return df_long


# /!\ AJOUT FONCTION LOAD DF_FINAL /!\
@st.cache_data
def _load_df_final_internal(file_path):
    """Charge et pr√©pare df_final. Mis en cache."""
    print(f"--- Executing _load_df_final_internal for {file_path} ---")
    if not os.path.exists(file_path):
        print(f"Error: df_final file not found: {file_path}")
        # Ne pas utiliser st.error ici, la fonction appelante le fera
        return None
    df = None
    try:
        # Essayer avec la virgule en premier, bas√© sur l'aper√ßu fourni
        df = pd.read_csv(file_path, sep=',', encoding='utf-8')
        print("--- df_final loaded successfully with sep=',' and encoding='utf-8'.")
    except Exception as e_comma:
        print(f"Warning: Failed reading df_final with sep=',': {e_comma}. Trying sep=';'...")
        try:
            df = pd.read_csv(file_path, sep=';', encoding='utf-8') # Essayer ;/utf-8
            print("--- df_final loaded successfully with sep=';' and encoding='utf-8'.")
        except Exception as e_semi:
            print(f"Error: Failed reading df_final with both sep=',' and sep=';': {e_semi}")
            traceback.print_exc()
            return None # √âchec du chargement

    if df is None:
        print(f"Error: Cannot read df_final file {file_path} with tested separators/encodings.")
        return None

    if df.empty:
        print(f"Warning: df_final file {file_path} is empty after read.")
        return df

    # --- Pr√©traitement sp√©cifique √† df_final ---
    # Convertir la date
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df.dropna(subset=['date'], inplace=True) # Important
        # Extraire ann√©e et mois pour faciliter les calculs
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        print("--- df_final: 'date' column processed, 'year' and 'month' extracted.")
    else:
        print("Error: 'date' column missing in df_final. Contextual info will fail.")
        return pd.DataFrame() # Date est essentielle

    # Assurer que les colonnes num√©riques sont bien num√©riques
    num_cols_context = ['population', 'nb_total_entreprise', 'tmoy_degc']
    for col in num_cols_context:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            print(f"--- df_final: Column '{col}' converted to numeric.")
        else:
             print(f"Warning: Expected context column '{col}' missing in df_final.")
             # Cr√©er la colonne avec NaN si elle manque ? Ou laisser tel quel. Laisser tel quel pour l'instant.

    # Correction de l'encodage potentiel du nom de r√©gion (copi√© depuis train_model.py)
    if 'region' in df.columns:
         df['region'] = df['region'].astype(str).str.replace('√É¬¥', '√¥').str.replace('√É¬®', '√®').str.replace('√É¬©', '√©').str.replace('√É¬ß', '√ß')
         print("--- df_final: Region names potentially corrected for encoding issues.")

    print(f"--- df_final data preprocessed. Shape: {df.shape} ---")
    return df

# =============================================================================
# --- 5. GETTER FUNCTIONS (Lazy Loading Logic using st.session_state) ---
# =============================================================================
# Ces fonctions sont l'interface publique pour acc√©der aux donn√©es.
# Elles utilisent les fonctions internes (_) pour charger si n√©cessaire.

def get_eco2mix_data():
    """R√©cup√®re les donn√©es Eco2mix (charge si n√©cessaire via la fonction interne)."""
    if 'eco2mix_df' not in st.session_state:
        print("--- Eco2mix data not in session state. Calling internal loader. ---")
        # /!\ CORRECTION: Utilise la variable d√©finie dans la section 1 /!\
        st.session_state.eco2mix_df = _load_eco2mix_internal(ECO2MIX_CSV_PATH)
    # Toujours retourner une copie pour √©viter la modification de l'√©tat en cache
    if st.session_state.eco2mix_df is not None:
        return st.session_state.eco2mix_df.copy()
    else:
        return None

def get_effectifs_data():
    """R√©cup√®re les donn√©es Effectifs (charge si n√©cessaire via la fonction interne)."""
    if 'effectifs_df' not in st.session_state:
        print("--- Effectifs data not in session state. Calling internal loader. ---")
        # /!\ CORRECTION: Utilise la variable d√©finie dans la section 1 /!\
        st.session_state.effectifs_df = _load_effectifs_internal(EFFECTIFS_CSV_PATH)
    if st.session_state.effectifs_df is not None:
        return st.session_state.effectifs_df.copy()
    else:
        return None

def get_soutirage_data():
    """R√©cup√®re les donn√©es Soutirage (charge si n√©cessaire via la fonction interne)."""
    if 'soutirage_df' not in st.session_state:
        print("--- Soutirage data not in session state. Calling internal loader. ---")
        # /!\ CORRECTION: Utilise la variable d√©finie dans la section 1 /!\
        st.session_state.soutirage_df = _load_soutirage_internal(SOUTIRAGE_CSV_PATH)
    if st.session_state.soutirage_df is not None:
        return st.session_state.soutirage_df.copy()
    else:
        return None

def get_temperature_data():
    """R√©cup√®re les donn√©es Temp√©rature (charge si n√©cessaire via la fonction interne)."""
    if 'temperature_df' not in st.session_state:
        print("--- Temperature data not in session state. Calling internal loader. ---")
        # /!\ CORRECTION: Utilise la variable d√©finie dans la section 1 /!\
        st.session_state.temperature_df = _load_temperature_internal(TEMPERATURE_CSV_PATH)
    if st.session_state.temperature_df is not None:
        return st.session_state.temperature_df.copy()
    else:
        return None

def get_population_data():
    """R√©cup√®re les donn√©es Population (format long) (charge si n√©cessaire via la fonction interne)."""
    if 'population_df_long' not in st.session_state:
        print("--- Population data (long format) not in session state. Calling internal loader. ---")
        # /!\ CORRECTION: Utilise la variable d√©finie dans la section 1 /!\
        st.session_state.population_df_long = _load_population_internal(POPULATION_CSV_PATH)
    if st.session_state.population_df_long is not None:
        return st.session_state.population_df_long.copy()
    else:
        return None


# /!\ AJOUT GETTER DF_FINAL /!\
def get_df_final_data():
    """R√©cup√®re les donn√©es df_final (charge si n√©cessaire via la fonction interne)."""
    if 'df_final_data' not in st.session_state:
        print("--- df_final data not in session state. Calling internal loader. ---")
        # Utilise la variable d√©finie dans la section 1 (qui √©tait d√©j√† correcte)
        st.session_state.df_final_data = _load_df_final_internal(DF_FINAL_CSV_PATH)
    # Toujours retourner une copie pour √©viter la modification de l'√©tat en cache
    if st.session_state.df_final_data is not None:
        return st.session_state.df_final_data.copy()
    else:
        return None


# =============================================================================
# --- 6. VISUALIZATIONS DICTIONARY ---
# =============================================================================
# (Code inchang√© ici)
visualizations_data = {
    "1. √âvolution de la consommation d'√©nergie en France (2013-2023)": {
        "category": "Consommation (Tendances & Saisons)", # Ancienne cat√©gorie
        "text": """Le graphique ci-dessus illustre l'√©volution de la consommation d'√©nergie globale (en MW) sur une
p√©riode proche de la d√©cennie. On observe des variations saisonni√®res marqu√©es, avec des pics de
consommation r√©guliers correspondant probablement aux p√©riodes hivernales, o√π la demande en
chauffage augmente consid√©rablement. Ces cycles montrent une tendance annuelle r√©p√©titive,
indiquant que la consommation √©nerg√©tique est influenc√©e de mani√®re significative par les conditions
climatiques et les habitudes de consommation. Les donn√©es mettent √©galement en √©vidence une
certaine stabilit√© dans les tendances g√©n√©rales de la consommation d'√©nergie au fil du temps."""
    },
    "2. Production et consommation √©lectrique : D√©fis de 2022": {
        "category": "Production & Mix √ânerg√©tique", # Ancienne cat√©gorie
        "text": """Le graphique met en √©vidence la comparaison entre la consommation d'√©lectricit√© (en rouge) et la
production totale d'√©lectricit√© (en bleu) en France pour l'ann√©e 2022, avec des p√©riodes de d√©ficit de
production illustr√©es par les zones en rose. Notamment, la consommation a souvent d√©pass√© la
production, en particulier lors des mois hivernaux, ce qui peut √™tre attribu√© √† une demande accrue en
chauffage. Cette situation a √©t√© exacerb√©e par l'indisponibilit√© de plusieurs r√©acteurs nucl√©aires
fran√ßais en 2022, due √† des probl√®mes de corrosion sous contrainte d√©tect√©s sur certaines
tuyauteries, entra√Ænant des arr√™ts prolong√©s pour maintenance et r√©parations.

Ces indisponibilit√©s ont conduit la France, habituellement exportatrice nette d'√©lectricit√©, √† importer de
l'√©lectricit√© pour r√©pondre √† la demande int√©rieure.

Ce visuel souligne l'importance cruciale de la gestion et de la maintenance des infrastructures de
production √©nerg√©tique pour assurer l'√©quilibre entre l'offre et la demande, particuli√®rement en p√©riode
de pointe.

**R√©f√©rences:**
- [Banque de France - Solde √©nerg√©tique en 2022](https://www.banque-france.fr/fr/publications-et-statistiques/publications/solde-energetique-en-2022-la-crise-de-la-production-electronucleaire-survenue-au-pire-moment)
- [Primeo Energie - √âtat des lieux du parc nucl√©aire fran√ßais](https://www.primeo-energie.fr/actuenergie/etat-des-lieux-du-parc-nucleaire-francais/)"""
    },
    "3. R√©partition r√©gionale de la consommation totale d'√©nergie en France (2013 √† 2023)": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Ce graphique circulaire pr√©sente la r√©partition de la consommation d'√©nergie par r√©gion en France.
On constate que l'√éle-de-France repr√©sente la part la plus importante, avec 15 % de la consommation
totale, ce qui peut s'expliquer par la densit√© de population et la concentration d'activit√©s √©conomiques
dans cette r√©gion. Elle est suivie par la r√©gion Auvergne-Rh√¥ne-Alpes (14 %), qui inclut de grandes
villes industrielles comme Lyon, et par le Grand Est (10,7 %), connu pour ses besoins √©nerg√©tiques
√©lev√©s dans le secteur industriel. √Ä l'inverse, des r√©gions comme le Centre-Val de Loire et la
Bourgogne-Franche-Comt√© affichent les parts les plus faibles, avec respectivement 4 % et 4,5 %. Ce
visuel met en lumi√®re les disparit√©s r√©gionales de la consommation √©nerg√©tique, qui sont influenc√©es
par la d√©mographie, l'industrialisation et les conditions climatiques locales."""
    },
    "4. √âvolution de la production d'√©nergie par source (2013-2022)": {
        "category": "Production & Mix √ânerg√©tique", # Ancienne cat√©gorie
        "text": """Ce graphique en barres empil√©es pr√©sente l'√©volution de la r√©partition des diff√©rentes sources
d'√©nergie en France de 2013 √† 2022. La production nucl√©aire (en gris) constitue la majeure partie de
la production √©nerg√©tique chaque ann√©e, confirmant le r√¥le pr√©dominant de cette source dans le mix
√©nerg√©tique fran√ßais. Cependant, on observe une l√©g√®re diminution de la part du nucl√©aire au cours
des derni√®res ann√©es, notamment en 2022, en raison des indisponibilit√©s prolong√©es de plusieurs
r√©acteurs nucl√©aires pour des maintenances et r√©parations.

Les sources renouvelables, telles que l'√©olien (en vert) et le solaire (en jaune), montrent une
croissance progressive au fil des ann√©es, bien que leur part reste encore limit√©e par rapport au
nucl√©aire et au thermique. L'hydraulique (en bleu) reste une source stable, mais d√©pend fortement
des conditions climatiques. Le thermique (en rouge), quant √† lui, joue un r√¥le de soutien pour
compenser les fluctuations des autres sources, notamment en p√©riode de forte demande ou de
d√©ficience du parc nucl√©aire.

Ce visuel met en √©vidence la transition √©nerg√©tique progressive en France, marqu√©e par une
diversification des sources d'√©nergie et une mont√©e en puissance des √©nergies renouvelables, bien
que le nucl√©aire reste un pilier central du syst√®me √©nerg√©tique fran√ßais."""
    },
    "5. Carte de chaleur de la consommation mensuelle d'√©lectricit√© (2013-2023)": {
        "category": "Consommation (Tendances & Saisons)", # Ancienne cat√©gorie
        "text": """La carte de chaleur mensuelle de la consommation √©lectrique met en √©vidence les variations
saisonni√®res de la demande √©nerg√©tique en France, r√©parties par ann√©e et par mois. On observe des
pics de consommation r√©currents en hiver, notamment en janvier et d√©cembre, marqu√©s par des
teintes rouges fonc√©es, ce qui correspond aux p√©riodes de forte demande li√©e au chauffage. √Ä
l'inverse, les mois d'√©t√©, en particulier de mai √† septembre, montrent une consommation nettement
plus faible, repr√©sent√©e par des teintes bleues.

L'ann√©e 2017 se distingue par un pic exceptionnel de consommation en janvier, probablement en
raison de conditions climatiques extr√™mes, comme une vague de froid. Les tendances g√©n√©rales
montrent une cyclicit√© annuelle stable, avec des hausses hivernales et des baisses estivales.

Ce visuel permet de mieux comprendre la relation entre les conditions climatiques et la demande en
√©lectricit√©, soulignant l'importance d'une planification √©nerg√©tique efficace pour r√©pondre aux besoins
accrus en p√©riode hivernale. Il met √©galement en avant l'impact des al√©as climatiques sur les
variations exceptionnelles de la consommation √©lectrique."""
    },
    "6. Distribution de la consommation √©lectrique moyenne par tranche de demie-heure par saison au niveau national": {
        "category": "Consommation (Tendances & Saisons)", # Ancienne cat√©gorie
        "text": """Le graphique en bo√Ætes √† moustaches (boxplot) pr√©sente la distribution de la consommation d'√©nergie
en France selon les saisons. On observe que la consommation est nettement plus √©lev√©e en hiver,
avec une m√©diane situ√©e autour de 6 000 MW et des valeurs maximales atteignant pr√®s de 16 000
MW, en raison de la forte demande li√©e au chauffage. L'automne suit avec une consommation
relativement √©lev√©e, tandis que le printemps et l'√©t√© affichent des niveaux de consommation plus
faibles.

Les bo√Ætes √† moustaches montrent √©galement une plus grande variabilit√© en hiver, avec de nombreux
points au-dessus des moustaches, indiquant des valeurs extr√™mes (pics de consommation). En
revanche, les saisons plus chaudes (printemps et √©t√©) pr√©sentent des distributions plus homog√®nes,
avec moins de valeurs extr√™mes.

Ce visuel met en √©vidence l'impact des conditions climatiques sur la demande en √©lectricit√©,
soulignant l'importance de la saisonnalit√© dans la gestion de la production et des infrastructures
√©nerg√©tiques. La forte consommation hivernale rappelle √©galement la n√©cessit√© d'anticiper les
p√©riodes de forte demande pour √©viter les tensions sur le r√©seau √©lectrique."""
    },
    "7. √âvolution temporelle par jour de la consommation √©lectrique moyenne par saison": {
        "category": "Consommation (Tendances & Saisons)", # Ancienne cat√©gorie
        "text": """Le graphique montre l'√©volution temporelle de la consommation moyenne d'√©lectricit√© par saison,
r√©partie tout au long de l'ann√©e. La courbe met en √©vidence des variations saisonni√®res bien
distinctes. En hiver (en orange), la consommation d'√©lectricit√© atteint ses plus hauts niveaux,
d√©passant 6 000 MW en raison des besoins accrus de chauffage. √Ä l'inverse, durant l'√©t√© (en rouge),
la consommation est au plus bas, avec une moyenne autour de 3 500 MW, ce qui refl√®te une moindre
utilisation de chauffage et une consommation globalement plus stable.

Le printemps (en vert) et l'automne (en bleu) affichent des niveaux interm√©diaires, mais la transition
entre les saisons montre une tendance claire : la consommation augmente fortement √† l'approche de
l'hiver et diminue progressivement apr√®s cette p√©riode. Les hausses et baisses sont r√©guli√®res et
suivent les cycles naturels des variations climatiques.

Ce visuel met en √©vidence la forte corr√©lation entre les saisons et la consommation √©nerg√©tique. Il
souligne l'importance de pr√©voir la demande √©nerg√©tique en fonction des p√©riodes de l'ann√©e afin
d'optimiser les capacit√©s de production et de r√©pondre aux besoins de mani√®re efficace."""
    },
    "8. Variations journali√®res de la consommation √©lectrique en France": {
        "category": "Consommation (Tendances & Saisons)", # Ancienne cat√©gorie
        "text": """Le graphique illustre la distribution horaire moyenne de la consommation d'√©lectricit√© sur une journ√©e
typique. On observe une tendance claire, avec deux pics principaux de consommation : le premier en
fin de matin√©e, entre 10 h et 13 h, et le second en d√©but de soir√©e, autour de 19 h. Ces pics peuvent
√™tre attribu√©s aux habitudes de la vie quotidienne, comme les activit√©s matinales (chauffage,
pr√©paration des repas, travail) et les besoins accrus en soir√©e apr√®s le retour √† domicile (√©clairage,
√©lectrom√©nagers, cuisine).

La consommation est la plus basse durant les heures nocturnes, entre 1 h et 5 h du matin, refl√©tant
une baisse de l'activit√© √©conomique et domestique. √Ä partir de 6 h, la demande commence √†
augmenter progressivement jusqu'√† atteindre le pic de la fin de matin√©e.

Ce visuel met en √©vidence les variations de la demande d'√©lectricit√© en fonction des moments de la
journ√©e, soulignant l'importance d'ajuster la production √©nerg√©tique pour r√©pondre aux besoins
sp√©cifiques de ces p√©riodes de forte consommation. Cette information est essentielle pour la gestion
des r√©seaux √©lectriques et l'optimisation des infrastructures √©nerg√©tiques."""
    },
    "9. Proportion de la production d'√©lectricit√© en France des √©nergies renouvelables et non-renouvelable": {
        "category": "Production & Mix √ânerg√©tique", # Ancienne cat√©gorie
        "text": """Ce graphique compare la production moyenne d'√©lectricit√© en France entre les sources renouvelables
et non-renouvelables. Les sources non-renouvelables dominent largement, repr√©sentant 75,9 % de la
production totale, tandis que les √©nergies renouvelables contribuent √† hauteur de 24,1 %.

La pr√©dominance des √©nergies non-renouvelables s'explique principalement par la forte d√©pendance
au nucl√©aire en France, qui constitue une part importante de la production non-renouvelable. En
revanche, les √©nergies renouvelables incluent des sources telles que l'hydro√©lectricit√©, l'√©olien, le
solaire et les bio√©nergies, qui, bien qu'en progression, restent minoritaires.

Ce visuel met en √©vidence le d√©fi de la transition √©nerg√©tique en France. Pour atteindre les objectifs
climatiques et r√©duire les √©missions de gaz √† effet de serre, il est crucial d'accro√Ætre la part des
√©nergies renouvelables dans le mix √©nerg√©tique. Cela n√©cessitera des investissements importants
dans les infrastructures renouvelables et des politiques favorisant leur d√©veloppement √† long terme."""
    },
    "10. Contribution des √©nergies renouvelables par saison": {
        "category": "Production & Mix √ânerg√©tique", # Ancienne cat√©gorie
        "text": """Le graphique en barres empil√©es montre la r√©partition moyenne des diff√©rentes sources d'√©nergie
renouvelable (√©olien, solaire, hydraulique et bio√©nergies) selon les saisons. On remarque que
l'hydraulique (en vert) constitue la part la plus importante de la production d'√©nergie renouvelable tout
au long de l'ann√©e, en raison de la disponibilit√© constante de cette ressource, notamment gr√¢ce aux
barrages et aux cours d'eau. Cependant, la production hydraulique tend √† √™tre plus √©lev√©e au
printemps, probablement en raison de la fonte des neiges et des pr√©cipitations.

La production √©olienne (en violet) est √©galement stable sur l'ann√©e, avec une l√©g√®re hausse en hiver
et au printemps, p√©riodes o√π les vents sont g√©n√©ralement plus forts. En revanche, la production
solaire (en bleu) atteint son pic durant l'√©t√©, gr√¢ce √† une exposition maximale au soleil.

Enfin, les bio√©nergies (en jaune) repr√©sentent une contribution constante et relativement stable √† la
production d'√©nergie renouvelable, quelle que soit la saison.

Ce visuel met en √©vidence la compl√©mentarit√© des diff√©rentes sources d'√©nergie renouvelable en
fonction des saisons, soulignant l'importance de diversifier les sources de production pour assurer un
approvisionnement √©nerg√©tique stable tout au long de l'ann√©e."""
    },
    "11. R√©partition r√©gionale de la consommation d'√©lectricit√©": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """La carte pr√©sente la consommation totale d'√©lectricit√© par r√©gion en France, exprim√©e en m√©gawatts
(MW). La distribution r√©gionale met en √©vidence des disparit√©s significatives entre les diff√©rentes
r√©gions. Les r√©gions les plus peupl√©es et √©conomiquement d√©velopp√©es, telles que l'√éle-de-France,
Auvergne-Rh√¥ne-Alpes et les Hauts-de-France, affichent les plus hauts niveaux de consommation,
repr√©sent√©s par les teintes les plus fonc√©es sur la carte. Cela s'explique par une forte concentration
de population, d'activit√©s industrielles et de services n√©cessitant une importante consommation
d'√©nergie.

√Ä l'inverse, des r√©gions comme la Bretagne, la Normandie ou les Pays de la Loire affichent une
consommation plus mod√©r√©e, en raison de leur densit√© de population plus faible et d'une moindre
concentration d'activit√©s √©nergivores.

Ce visuel met en √©vidence l'importance des facteurs d√©mographiques et √©conomiques dans la
r√©partition de la consommation √©lectrique √† l'√©chelle r√©gionale. Il souligne √©galement la n√©cessit√©
d'adapter les politiques √©nerg√©tiques r√©gionales pour r√©pondre aux besoins sp√©cifiques de chaque
territoire, en prenant en compte les sp√©cificit√©s locales en mati√®re de production et de consommation."""
    },
    "12. Production √©lectrique : Disparit√©s r√©gionales": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Cette carte montre la production totale d'√©lectricit√© par r√©gion en France, exprim√©e en m√©gawatts
(MW). Les teintes de bleu indiquent les variations de production entre les r√©gions, avec les r√©gions
les plus productrices repr√©sent√©es par les teintes les plus fonc√©es. On constate que les r√©gions du
Grand Est, d'Auvergne-Rh√¥ne-Alpes et du Centre-Val de Loire se distinguent comme les principaux
p√¥les de production √©lectrique. Cela s'explique par la pr√©sence de nombreuses centrales nucl√©aires
dans ces r√©gions, qui constituent une part importante du mix √©nerg√©tique fran√ßais.

En revanche, des r√©gions comme la Bretagne et la Normandie affichent une production plus faible, ce
qui peut s'expliquer par une moindre densit√© de sites de production √©lectrique, notamment les
centrales thermiques et nucl√©aires.

Ce visuel met en lumi√®re les disparit√©s r√©gionales en termes de production d'√©nergie et souligne
l'importance strat√©gique de certaines r√©gions dans l'approvisionnement √©lectrique national. Il r√©v√®le
√©galement la n√©cessit√© d'adapter les infrastructures de production aux besoins sp√©cifiques de chaque
territoire pour assurer une meilleure gestion du r√©seau √©lectrique."""
    },
    "13. Croissance d√©mographique r√©gionale (1990-2024)": { # Note: Titre incoh√©rent avec le texte qui parle de pop 2024 et pas de croissance
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Cette carte repr√©sente la population totale par r√©gion en France pour l'ann√©e 2024. Les teintes
violettes indiquent les variations de densit√© de population, avec les r√©gions les plus peupl√©es
repr√©sent√©es par les couleurs les plus fonc√©es. L'√éle-de-France se distingue comme la r√©gion la plus
dens√©ment peupl√©e, en raison de la pr√©sence de Paris et de sa r√©gion m√©tropolitaine. Elle est suivie
par les r√©gions Auvergne-Rh√¥ne-Alpes, Provence-Alpes-C√¥te d'Azur et Occitanie, qui comptent
√©galement des m√©tropoles importantes telles que Lyon, Marseille et Toulouse.

Les r√©gions moins peupl√©es, comme la Bretagne, la Bourgogne-Franche-Comt√© et la Normandie,
apparaissent dans des teintes plus claires. Ces disparit√©s d√©mographiques influencent directement
les besoins √©nerg√©tiques de chaque r√©gion, les zones les plus dens√©ment peupl√©es √©tant
susceptibles de consommer davantage d'√©lectricit√©."""
    },
    "14. Croissance de la population totale en France (1990-2024)": {
        "category": "D√©mographie Nationale", # Ancienne cat√©gorie
        "text": """Ce graphique montre l'√©volution de la population totale en France, exprim√©e en millions d'habitants,
entre 1990 et 2024. La courbe bleue repr√©sente la population totale au fil des ann√©es, tandis que la
ligne rouge pointill√©e indique la tendance de croissance moyenne sur la p√©riode. La population a
connu une augmentation r√©guli√®re, passant d'environ 56 millions en 1990 √† pr√®s de 66 millions en
2024. Cette croissance √©quivaut √† une augmentation annuelle moyenne de 0,3 million d'habitants,
soit un taux de croissance d'environ 0,53 % par an.

Le graphique met √©galement en √©vidence des p√©riodes de croissance l√©g√®rement plus rapide dans
les ann√©es 1990 et au d√©but des ann√©es 2000. La croissance semble cependant devenir plus
mod√©r√©e ces derni√®res ann√©es, ce qui pourrait s'expliquer par des facteurs tels que la diminution des
taux de natalit√© ou les politiques migratoires.

Ce visuel souligne la tendance d√©mographique √† long terme en France, qui a des implications
importantes pour la planification des infrastructures et des services publics, y compris la
consommation √©nerg√©tique. La hausse constante de la population entra√Æne n√©cessairement une
augmentation de la demande en √©nergie et en ressources, ce qui doit √™tre pris en compte dans les
politiques de gestion de l'√©nergie et de d√©veloppement durable."""
    },
    "15. R√©partition de la population par r√©gion en France au 31 d√©cembre 2024": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Ce graphique en barres horizontales pr√©sente la population estim√©e par r√©gion en France au 31
d√©cembre 2024, exprim√©e en millions d'habitants. La r√©gion √éle-de-France se distingue nettement
avec plus de 12 millions d'habitants, confirmant son r√¥le de p√¥le d√©mographique majeur. Viennent
ensuite les r√©gions Auvergne-Rh√¥ne-Alpes et Nouvelle-Aquitaine, qui comptent respectivement
environ 8 et 6 millions d'habitants. Ces r√©gions regroupent de grandes m√©tropoles telles que Lyon,
Bordeaux et Toulouse, contribuant ainsi √† leur densit√© de population.

√Ä l'autre extr√©mit√© du spectre, la Corse est la r√©gion la moins peupl√©e avec environ 0,3 million
d'habitants. Les r√©gions telles que le Centre-Val de Loire, la Bourgogne-Franche-Comt√©, la
Normandie et la Bretagne pr√©sentent des populations relativement stables et moins concentr√©es par
rapport aux grandes r√©gions m√©tropolitaines.

Ce visuel met en √©vidence les disparit√©s r√©gionales en termes de population, qui influencent
directement les besoins en infrastructures, en services publics et en ressources √©nerg√©tiques. Les
r√©gions les plus peupl√©es sont celles qui n√©cessitent le plus d'√©nergie pour alimenter les m√©nages,
les industries et les services. Ces informations sont cruciaux pour adapter les politiques √©nerg√©tiques
aux besoins sp√©cifiques de chaque r√©gion."""
    },
    "16. Croissance annuelle moyenne de la population par r√©gion (1990-2024)": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Ce graphique en barres horizontales montre la croissance annuelle moyenne de la population par
r√©gion en France entre 1990 et 2024. L'√éle-de-France enregistre la plus forte croissance moyenne,
d√©passant les 50 000 habitants par an, en raison de son attractivit√© √©conomique et de son r√¥le de
p√¥le central d'activit√©s. Suivent les r√©gions Occitanie, Auvergne-Rh√¥ne-Alpes et Nouvelle-Aquitaine,
qui connaissent √©galement une forte croissance d√©mographique, attirant de nouveaux habitants
gr√¢ce √† leur qualit√© de vie et √† leurs dynamiques √©conomiques.

Les r√©gions ayant une croissance moyenne plus mod√©r√©e incluent la Bourgogne-Franche-Comt√©, la
Corse et la Normandie. Cela peut s'expliquer par des facteurs comme une moindre attractivit√©
√©conomique ou un vieillissement de la population.

Ce visuel met en √©vidence les diff√©rences r√©gionales en termes de croissance d√©mographique, qui
influencent directement la planification urbaine, les infrastructures et les politiques publiques. Les
r√©gions √† forte croissance devront faire face √† des d√©fis en mati√®re d'am√©nagement du territoire, de
logement, et de gestion des ressources, notamment √©nerg√©tiques."""
    },
    "17. √âvolution de la temp√©rature moyenne mensuelle en France (2016-2025)": {
        "category": "Climat & Impact √ânergie", # Ancienne cat√©gorie
        "text": """Le graphique pr√©sente l'√©volution de la temp√©rature moyenne mensuelle sur plusieurs ann√©es,
accompagn√©e d'une tendance g√©n√©rale de r√©gression lin√©aire repr√©sent√©e par la ligne rouge. La
courbe bleue met en √©vidence les fluctuations saisonni√®res typiques de la temp√©rature, avec des pics
√©lev√©s en √©t√© et des creux en hiver. Cependant, la ligne de tendance montre une augmentation
progressive des temp√©ratures moyennes au fil des ans.

La variation annuelle moyenne indiqu√©e est de 0,218 ¬∞C, soit une hausse de 3,25 % par an. Cette
tendance √† la hausse refl√®te un r√©chauffement climatique global, avec une augmentation constante
des temp√©ratures moyennes sur la p√©riode observ√©e. Ce ph√©nom√®ne est coh√©rent avec les
pr√©occupations li√©es au changement climatique, qui impacte de nombreux aspects, notamment la
consommation √©nerg√©tique pour le chauffage et la climatisation.

Ce visuel souligne l'importance d'int√©grer les pr√©visions climatiques dans la gestion des ressources
√©nerg√©tiques. Une hausse continue des temp√©ratures peut modifier les besoins √©nerg√©tiques
saisonniers, avec une probable augmentation de la demande estivale en climatisation et une
diminution des besoins hivernaux en chauffage."""
    },
    "18. Carte des temp√©ratures moyennes annuelles par r√©gion en France": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Cette carte montre la temp√©rature moyenne annuelle par r√©gion en France. Les r√©gions du nord et du
centre du pays, comme les Hauts-de-France, la Normandie, le Grand Est, et l'√éle-de-France,
pr√©sentent les temp√©ratures moyennes les plus basses, repr√©sent√©es par les teintes bleues. √Ä
l'oppos√©, les r√©gions du sud, telles que la Provence-Alpes-C√¥te d'Azur, l'Occitanie et surtout la Corse,
affichent des temp√©ratures plus √©lev√©es, avec des teintes allant vers le rouge.

La Corse se distingue comme la r√©gion ayant la temp√©rature moyenne la plus √©lev√©e, d√©passant les
16 ¬∞C. Ce contraste nord-sud est caract√©ristique du climat fran√ßais, avec des temp√©ratures plus
froides dans les r√©gions septentrionales et plus chaudes dans les r√©gions m√©diterran√©ennes.

Ce visuel met en √©vidence les variations climatiques r√©gionales, qui influencent les besoins
√©nerg√©tiques locaux. Les r√©gions plus froides n√©cessitent davantage de chauffage en hiver, tandis
que les r√©gions plus chaudes peuvent avoir une plus forte demande en climatisation durant les mois
estivaux. Ces disparit√©s doivent √™tre prises en compte dans la planification des infrastructures
√©nerg√©tiques pour adapter les ressources aux sp√©cificit√©s climatiques locales."""
    },
    "19. Carte de chaleur des temp√©ratures moyennes par r√©gion et mois en France": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie
        "text": """Cette carte de chaleur illustre les temp√©ratures moyennes mensuelles par r√©gion en France,
permettant de visualiser les variations saisonni√®res et g√©ographiques tout au long de l'ann√©e. Les
r√©gions m√©ridionales, comme la Corse et la Provence-Alpes-C√¥te d'Azur, se d√©marquent par des
temp√©ratures plus √©lev√©es, notamment durant les mois d'√©t√© (juin, juillet, ao√ªt), o√π elles atteignent
jusqu'√† 25 ¬∞C en moyenne. En revanche, les r√©gions du nord et du centre, telles que les
Hauts-de-France, le Grand Est et la Bourgogne-Franche-Comt√©, affichent des temp√©ratures
moyennes plus basses, particuli√®rement en hiver (janvier et f√©vrier), avec des valeurs inf√©rieures √† 5 ¬∞C.

Les diff√©rences saisonni√®res sont tr√®s marqu√©es, avec une hausse significative des temp√©ratures
entre le printemps et l'√©t√©, suivie d'une baisse progressive √† l'approche de l'automne et de l'hiver. Ce
ph√©nom√®ne est particuli√®rement visible en Corse, qui conna√Æt les temp√©ratures les plus √©lev√©es en
√©t√©, d√©passant les 25 ¬∞C.

Ce visuel met en √©vidence la forte influence des saisons sur les variations de temp√©rature en France.
Ces diff√©rences doivent √™tre prises en compte dans les strat√©gies √©nerg√©tiques r√©gionales, car elles
affectent les besoins de chauffage en hiver et de climatisation en √©t√©. La carte permet √©galement
d'identifier les r√©gions les plus susceptibles de faire face √† des vagues de chaleur, notamment dans le
sud du pays, ce qui peut avoir un impact sur la demande √©nerg√©tique et les infrastructures."""
    },
    "20. R√©partition des temp√©ratures moyennes en France : Histogramme et courbe de distribution": {
        "category": "Climat & Impact √ânergie", # Ancienne cat√©gorie
        "text": """Le graphique repr√©sente la r√©partition des temp√©ratures moyennes en France sous forme
d'histogramme, accompagn√© d'une courbe de densit√©. La distribution des temp√©ratures suit une
forme en cloche, proche d'une distribution normale, avec une fr√©quence maximale autour de 10 √† 15
¬∞C. Cela indique que la majorit√© des temp√©ratures moyennes observ√©es en France se situent dans
cette fourchette.

Les temp√©ratures plus extr√™mes, inf√©rieures √† 0 ¬∞C ou sup√©rieures √† 25 ¬∞C, sont beaucoup moins
fr√©quentes, ce qui est coh√©rent avec le climat temp√©r√© de la France. On observe une l√©g√®re
asym√©trie vers la droite, ce qui sugg√®re qu'il y a une proportion l√©g√®rement plus √©lev√©e de
temp√©ratures moyennes √©lev√©es par rapport aux temp√©ratures basses.

Ce visuel permet de mieux comprendre les conditions climatiques g√©n√©rales en France, en mettant
en √©vidence que la majorit√© des temp√©ratures moyennes sont mod√©r√©es. Cela a des implications
importantes pour les besoins √©nerg√©tiques saisonniers, notamment en mati√®re de chauffage en hiver
et de climatisation en √©t√©, les p√©riodes de temp√©ratures extr√™mes √©tant plus rares."""
    },
    "21. √âvolution des temp√©ratures moyennes annuelles en France (2016-2024)": {
        "category": "Climat & Impact √ânergie", # Ancienne cat√©gorie
        "text": """Le graphique montre l'√©volution des temp√©ratures moyennes annuelles en France sur une p√©riode
allant de 2016 √† 2024. La courbe rouge liss√©e met en √©vidence les fluctuations interannuelles des
temp√©ratures, tandis que les points noirs repr√©sentent les donn√©es r√©elles pour chaque ann√©e. On
observe une tendance g√©n√©rale √† la hausse des temp√©ratures, bien que cette tendance soit marqu√©e
par des cycles de variation.

Les ann√©es 2020 et 2021 montrent une l√©g√®re baisse des temp√©ratures moyennes, mais cette baisse
est suivie d'une remont√©e notable √† partir de 2022, culminant en 2024. Ces variations peuvent √™tre
li√©es √† des √©v√©nements climatiques sp√©cifiques ou √† des ph√©nom√®nes m√©t√©orologiques ponctuels.

Ce visuel souligne l'importance de suivre les tendances climatiques √† long terme pour mieux
comprendre l'impact du changement climatique. Bien que les variations annuelles puissent masquer
la tendance g√©n√©rale, l'augmentation des temp√©ratures moyennes sur plusieurs ann√©es est un
indicateur clair du r√©chauffement climatique, avec des implications sur les besoins √©nerg√©tiques, les
ressources naturelles et la gestion des infrastructures."""
    },
    "22. R√©partition de la consommation d'√©lectricit√© par secteur d'activit√© √©conomique": {
        "category": "Consommation par Secteur", # Ancienne cat√©gorie
        "text": """Ce graphique circulaire pr√©sente la r√©partition de la consommation d'√©lectricit√© en France par secteur
d'activit√©. La grande industrie domine largement la consommation avec 66 % du total, ce qui refl√®te le
r√¥le important de l'industrie lourde et des processus industriels dans la demande √©nerg√©tique
nationale. Cela inclut des secteurs tels que la m√©tallurgie, la chimie, et les raffineries, qui n√©cessitent
une alimentation √©nerg√©tique continue et intensive.

Le secteur "Autre" repr√©sente 23,8 % de la consommation totale. Cette cat√©gorie peut inclure les
usages r√©sidentiels, les infrastructures publiques, et d'autres activit√©s moins √©nergivores mais
toujours essentielles, comme les transports et l'agriculture.

Le secteur tertiaire, qui regroupe les bureaux, les commerces et les services, repr√©sente 10,2 % de la
consommation totale. Bien que moins gourmand en √©nergie que la grande industrie, ce secteur est
n√©anmoins important, notamment dans les r√©gions fortement urbanis√©es.

Ce visuel met en √©vidence l'impact majeur du secteur industriel sur la demande √©nerg√©tique en
France. Il souligne la n√©cessit√© de cibler les industries pour toute initiative visant √† r√©duire la
consommation √©nerg√©tique ou √† am√©liorer l'efficacit√© √©nerg√©tique. Par ailleurs, bien que le secteur
tertiaire consomme moins d'√©nergie, il joue un r√¥le important dans les villes et pourrait b√©n√©ficier
d'actions visant √† promouvoir les √©nergies renouvelables et l'efficacit√© √©nerg√©tique dans les b√¢timents
commerciaux et administratifs."""
    },
    "23. Top 5 des r√©gions avec le plus d'entreprises (2019)": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie -> Devrait √™tre √âconomie/Secteur ? Mais focus R√©gional. Gardons R√©gional.
        "text": """Ce graphique circulaire illustre la r√©partition des entreprises dans les cinq r√©gions fran√ßaises
comptant le plus grand nombre d'entreprises. L'√éle-de-France domine largement avec 36,3 % du total
des entreprises, soit plus d'un million d'entreprises, confirmant son r√¥le de moteur √©conomique du
pays. Cette concentration est due √† la pr√©sence de Paris, capitale √©conomique et financi√®re, ainsi
qu'√† l'attractivit√© de la r√©gion pour les si√®ges sociaux et les start-ups.

L'Auvergne-Rh√¥ne-Alpes se classe en deuxi√®me position avec 19 % des entreprises, suivie de la
Provence-Alpes-C√¥te d'Azur (16 %), de l'Occitanie (14,9 %) et de la Nouvelle-Aquitaine (13,7 %). Ces
r√©gions disposent d'importantes m√©tropoles √©conomiques comme Lyon, Marseille, Toulouse et
Bordeaux, qui contribuent √† la cr√©ation et au d√©veloppement d'entreprises.

Ce visuel met en lumi√®re l'in√©galit√© dans la r√©partition des entreprises √† travers le territoire fran√ßais.
Les r√©gions les plus dynamiques √©conomiquement concentrent une grande partie des activit√©s
entrepreneuriales, ce qui peut avoir un impact direct sur les besoins en infrastructures, en √©nergie et
en services. Cette r√©partition refl√®te √©galement les disparit√©s √©conomiques r√©gionales, qui doivent
√™tre prises en compte dans les politiques de d√©veloppement territorial et √©conomique."""
    },
    "24. Consommation d'√©lectricit√© par secteur d'activit√© √©conomique et par r√©gion (2023)": {
        "category": "Analyses R√©gionales (√ânergie & Population)", # Ancienne cat√©gorie -> Croise R√©gional et Secteur. Mettons dans R√©gional.
        "text": """Ce graphique √† barres empil√©es montre la consommation totale d'√©lectricit√© par secteur d'activit√© et
par r√©gion en France pour l'ann√©e 2023. La consommation est d√©compos√©e en trois principaux
secteurs : la grande industrie (en bleu), le secteur tertiaire (en vert) et les autres secteurs (en orange).

Les Hauts-de-France se distinguent comme la r√©gion ayant la plus forte consommation d'√©nergie,
principalement due √† la grande industrie, qui repr√©sente la majeure partie de la consommation dans
cette r√©gion. Cela peut √™tre expliqu√© par la pr√©sence d'industries lourdes, telles que les industries
m√©tallurgiques et chimiques. L'Auvergne-Rh√¥ne-Alpes et la Provence-Alpes-C√¥te d'Azur suivent
√©galement avec une consommation industrielle √©lev√©e, tout en ayant une contribution notable du
secteur tertiaire.

En revanche, l'√éle-de-France, bien que tr√®s peupl√©e, pr√©sente une r√©partition diff√©rente de sa
consommation √©nerg√©tique. La consommation dans cette r√©gion est domin√©e par le secteur tertiaire,
en raison de la forte concentration d'entreprises de services, de bureaux et d'activit√©s √©conomiques
non industrielles.

Ce visuel met en √©vidence les disparit√©s r√©gionales dans la consommation √©nerg√©tique selon les
secteurs d'activit√©. Les r√©gions √† forte industrialisation consomment davantage d'√©nergie dans le
secteur industriel, tandis que les r√©gions ax√©es sur les services, comme l'√éle-de-France, voient une
plus grande part de leur consommation √©nerg√©tique provenir du secteur tertiaire. Cette r√©partition doit
√™tre prise en compte pour adapter les politiques √©nerg√©tiques aux besoins sp√©cifiques de chaque
r√©gion et secteur."""
    },
    "25. Evolution de la consommation √©lectrique par secteur d'activit√© √©conomique sur une journ√©e": {
        "category": "Consommation par Secteur", # Ancienne cat√©gorie
        "text": """Le graphique montre l'√©volution de la consommation moyenne d'√©lectricit√© par secteur d'activit√© au
cours d'une journ√©e typique. Trois secteurs sont repr√©sent√©s : la grande industrie (en orange), le
secteur tertiaire (en vert) et les autres secteurs (en bleu).

La grande industrie affiche une consommation relativement constante tout au long de la journ√©e,
autour de 700 MW. Cela s'explique par le fonctionnement continu des processus industriels, qui
n√©cessitent une alimentation √©nerg√©tique stable, ind√©pendamment des heures de la journ√©e.

Le secteur tertiaire, en revanche, pr√©sente une variation plus importante au fil de la journ√©e. La
consommation augmente progressivement √† partir de 6 h du matin, atteignant un pic autour de midi,
puis redescend en fin de journ√©e. Cette tendance est coh√©rente avec les horaires d'ouverture des
bureaux et des commerces.

La cat√©gorie "Autre" montre une consommation stable, sans variations significatives au cours de la
journ√©e. Cela pourrait inclure des usages r√©sidentiels ou des infrastructures n√©cessitant un
approvisionnement constant.

Ce visuel met en √©vidence les diff√©rences de comportement entre les secteurs en termes de
consommation √©nerg√©tique. Alors que la grande industrie n√©cessite une alimentation continue, la
consommation du secteur tertiaire est plus li√©e aux horaires de travail. Cette distinction est importante
pour optimiser la gestion de l'approvisionnement en √©lectricit√©, notamment en ajustant la production
aux p√©riodes de forte demande."""
    },
    "26. Relation entre la temp√©rature moyenne et la consommation d'√©lectricit√© en France": {
        "category": "Climat & Impact √ânergie", # Ancienne cat√©gorie
        "text": """Ce graphique de dispersion (scatter plot) illustre la relation entre la temp√©rature moyenne (en ¬∞C) et
la consommation d'√©lectricit√© (en MW) en France. On observe une relation non lin√©aire
caract√©ristique : la consommation d'√©lectricit√© est plus √©lev√©e aux extr√™mes de la courbe de
temp√©rature, c'est-√†-dire lorsque les temp√©ratures sont tr√®s basses (en dessous de 5 ¬∞C) ou tr√®s
√©lev√©es (au-dessus de 20 ¬∞C). Cette relation traduit l'impact des besoins en chauffage et en
climatisation sur la consommation √©nerg√©tique.

Lorsque les temp√©ratures sont basses, la consommation d'√©lectricit√© augmente de mani√®re
significative, principalement en raison de l'utilisation accrue des syst√®mes de chauffage √©lectrique.
Inversement, on observe √©galement une augmentation de la consommation lorsque les temp√©ratures
sont √©lev√©es, ce qui correspond √† une demande accrue en climatisation et en ventilation.

La consommation d'√©lectricit√© est plus mod√©r√©e pour des temp√©ratures comprises entre 10 ¬∞C et 20
¬∞C, correspondant √† une plage o√π les besoins de chauffage et de climatisation sont r√©duits.

Ce visuel met en lumi√®re la forte d√©pendance de la consommation √©lectrique aux conditions
climatiques. Il souligne l'importance de pr√©voir la gestion de la demande √©nerg√©tique en fonction des
variations saisonni√®res de la temp√©rature, notamment pour √©viter des pics de consommation lors
d'√©pisodes de froid extr√™me ou de vagues de chaleur."""
    },
    "27. Consommation √©lectrique moyenne par cat√©gorie de temp√©rature": {
        "category": "Climat & Impact √ânergie", # Ancienne cat√©gorie
        "text": """Ce graphique √† barres pr√©sente la consommation √©lectrique moyenne en fonction des cat√©gories de
temp√©rature. Les diff√©rentes cat√©gories sont class√©es de "Tr√®s froid" (< 0 ¬∞C) √† "Tr√®s chaud" (> 30
¬∞C). On observe que la consommation √©lectrique atteint son pic dans les conditions de "Tr√®s froid",
avec une consommation moyenne d√©passant les 300 000 MW. Cette forte demande est due √†
l'utilisation massive des syst√®mes de chauffage √©lectrique pendant les p√©riodes de temp√©ratures tr√®s basses.

√Ä l'inverse, les cat√©gories de temp√©rature "Mod√©r√©" (10-20 ¬∞C) et "Chaud" (20-30 ¬∞C) affichent les
consommations les plus faibles. Cela s'explique par le fait que dans cette plage de temp√©ratures, les
besoins en chauffage et en climatisation sont r√©duits.

La consommation remonte l√©g√®rement dans la cat√©gorie "Tr√®s chaud" (> 30 ¬∞C), en raison de
l'augmentation de l'utilisation des syst√®mes de climatisation pendant les vagues de chaleur.

Ce visuel met en √©vidence la corr√©lation entre les conditions climatiques extr√™mes (froid ou chaud) et
la consommation √©nerg√©tique. Les p√©riodes de temp√©ratures extr√™mes entra√Ænent une forte demande
en √©nergie, soulignant l'importance de pr√©voir des strat√©gies de gestion de la demande √©nerg√©tique,
notamment en renfor√ßant l'efficacit√© √©nerg√©tique des b√¢timents pour le chauffage et la climatisation."""
    },
    "28. Impact des variations de temp√©rature sur la consommation √©lectrique": {
        "category": "Climat & Impact √ânergie", # Ancienne cat√©gorie
        "text": """Ce graphique combine une courbe de temp√©rature moyenne mensuelle (en rouge) et des barres
repr√©sentant la consommation √©lectrique mensuelle (en bleu) en France. Il met en √©vidence la
relation inverse entre la temp√©rature moyenne et la consommation √©lectrique. En hiver, lorsque les
temp√©ratures sont les plus basses (notamment en janvier et d√©cembre), la consommation √©lectrique
atteint son pic, principalement en raison des besoins accrus de chauffage.

√Ä l'inverse, durant les mois les plus chauds (de juin √† ao√ªt), les temp√©ratures atteignent leur pic, mais
la consommation √©lectrique diminue l√©g√®rement. Cependant, on remarque que la consommation ne
baisse pas autant qu'on pourrait s'y attendre, ce qui peut √™tre attribu√© √† l'utilisation croissante des
climatiseurs pendant les vagues de chaleur estivales.

Ce visuel met en √©vidence l'importance des variations saisonni√®res sur la consommation √©lectrique. Il
souligne la n√©cessit√© de g√©rer les pics de demande √©nerg√©tique en hiver, tout en anticipant une
augmentation de la demande estivale li√©e au r√©chauffement climatique. Les politiques √©nerg√©tiques
doivent prendre en compte ces variations saisonni√®res pour assurer un approvisionnement stable tout
au long de l'ann√©e."""
    }
}

# --- /!\ MODIFICATION : Suppression de "Analyses R√©gionales" ---
# --- Nouvelles Cat√©gories Ordonn√©es (SANS Analyses R√©gionales) ---
NEW_CATEGORIES_ORDERED = [
    "üìà Consommation : Tendances & Rythmes",
    "üè≠ Production & Mix √ânerg√©tique",
    # "üó∫Ô∏è Analyses R√©gionales", # <-- SUPPRIM√â
    "‚òÄÔ∏è Climat & M√©t√©o : Impact √ânergie",
    "üè¢ Consommation par Secteur & √âconomie",
    "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ D√©mographie"
]

# --- Mapping des anciennes cat√©gories vers les nouvelles (pour la logique de regroupement) ---
# Note: 'Analyses R√©gionales (√ânergie & Population)' n'a plus de destination directe.
# Sa logique sera g√©r√©e au cas par cas dans la boucle de regroupement ci-dessous.
OLD_TO_NEW_CATEGORY_MAP = {
    "Consommation (Tendances & Saisons)": "üìà Consommation : Tendances & Rythmes",
    "Production & Mix √ânerg√©tique": "üè≠ Production & Mix √ânerg√©tique",
    "Analyses R√©gionales (√ânergie & Population)": None, # Sera trait√© sp√©cifiquement
    "D√©mographie Nationale": "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ D√©mographie",
    "Climat & Impact √ânergie": "‚òÄÔ∏è Climat & M√©t√©o : Impact √ânergie",
    "Consommation par Secteur": "üè¢ Consommation par Secteur & √âconomie"
}

# --- Regrouper les visualisations par NOUVELLE cat√©gorie ---
visualizations_by_new_category = {cat: [] for cat in NEW_CATEGORIES_ORDERED}
for original_key, details in visualizations_data.items():
    old_category = details["category"]
    new_category = None # R√©initialiser pour chaque visualisation

    # /!\ MODIFICATION : Logique de r√©affectation des visualisations de l'ancienne cat√©gorie "Analyses R√©gionales" ---
    if old_category == "Analyses R√©gionales (√ânergie & Population)":
        # R√©affectation bas√©e sur le contenu de la visualisation (cl√© originale)
        if original_key in ["3. R√©partition r√©gionale de la consommation totale d'√©nergie en France (2013 √† 2023)",
                           "11. R√©partition r√©gionale de la consommation d'√©lectricit√©"]:
             new_category = "üìà Consommation : Tendances & Rythmes"
        elif original_key in ["12. Production √©lectrique : Disparit√©s r√©gionales"]:
             new_category = "üè≠ Production & Mix √ânerg√©tique"
        elif original_key in ["13. Croissance d√©mographique r√©gionale (1990-2024)", # Pop 2024 map
                           "15. R√©partition de la population par r√©gion en France au 31 d√©cembre 2024",
                           "16. Croissance annuelle moyenne de la population par r√©gion (1990-2024)"]:
             new_category = "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ D√©mographie"
        elif original_key in ["18. Carte des temp√©ratures moyennes annuelles par r√©gion en France",
                           "19. Carte de chaleur des temp√©ratures moyennes par r√©gion et mois en France"]:
             new_category = "‚òÄÔ∏è Climat & M√©t√©o : Impact √ânergie"
        elif original_key in ["23. Top 5 des r√©gions avec le plus d'entreprises (2019)",
                           "24. Consommation d'√©lectricit√© par secteur d'activit√© √©conomique et par r√©gion (2023)"]:
             new_category = "üè¢ Consommation par Secteur & √âconomie"
        else:
            # Fallback au cas o√π une visualisation de cette cat√©gorie n'est pas list√©e ci-dessus
             print(f"Avertissement: Visualisation '{original_key}' de cat√©gorie 'Analyses R√©gionales (√ânergie & Population)' non explicitement r√©affect√©e. Placement dans la premi√®re cat√©gorie.")
             new_category = NEW_CATEGORIES_ORDERED[0] # Ou une autre cat√©gorie par d√©faut
    else:
        # Pour les autres cat√©gories, utiliser le mapping standard
        new_category = OLD_TO_NEW_CATEGORY_MAP.get(old_category)

    # Cas particulier: la 14 est D√©mographie Nationale
    if original_key == "14. Croissance de la population totale en France (1990-2024)":
        new_category = "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ D√©mographie"


    if new_category and new_category in visualizations_by_new_category:
        visualizations_by_new_category[new_category].append(original_key)
    else:
        print(f"Avertissement: Impossible de mapper la visualisation '{original_key}' (ancienne cat: '{old_category}') vers une nouvelle cat√©gorie valide ou cat√©gorie non trouv√©e: '{new_category}'.")
        # Optionnel: Mettre dans une cat√©gorie "Autre" ou la premi√®re par d√©faut si elle existe encore
        if NEW_CATEGORIES_ORDERED:
            visualizations_by_new_category[NEW_CATEGORIES_ORDERED[0]].append(original_key)


# Trier les visualisations dans chaque cat√©gorie par leur num√©ro
for cat in visualizations_by_new_category:
    visualizations_by_new_category[cat].sort(key=lambda x: int(x.split('.')[0]))

# --- Fonction pour cr√©er des titres d'affichage plus courts ---
def create_display_title(original_key):
    try:
        # Enlever le num√©ro et le point, garder le reste
        title_part = original_key.split('.', 1)[1].strip()
        # Raccourcissements simples (peut √™tre am√©lior√©)
        replacements = {
            "consommation d'√©nergie": "Conso. √ânergie",
            "consommation d'√©lectricit√©": "Conso. √âlec.",
            "production d'√©lectricit√©": "Prod. √âlec.",
            "production d'√©nergie": "Prod. √ânergie",
            "r√©partition r√©gionale": "R√©part. R√©gionale",
            "√©volution temporelle": "√âvol. Temporelle",
            "temp√©ratures moyennes": "Temp. Moyennes",
            "secteur d'activit√© √©conomique": "Secteur √âco.",
            "√©nergies renouvelables": "EnR",
            "France": "FR",
            "par r√©gion": "/ R√©gion",
            "par saison": "/ Saison",
            "par mois": "/ Mois",
            "sur une journ√©e": "/ Jour",
            "au niveau national": "(National)",
            "annuelles": "annuelles", # Garder ou raccourcir ?
            "mensuelle": "mensuelle"
        }
        for old, new in replacements.items():
            title_part = title_part.replace(old, new)

        # Limiter la longueur si n√©cessaire
        max_len = 70 # Ajuster si besoin
        if len(title_part) > max_len:
            title_part = title_part[:max_len-3] + "..."
        return title_part
    except Exception: # Fallback en cas d'erreur de split ou autre
        return original_key # Retourne la cl√© originale si le formatage √©choue

# --- Cr√©er un mapping Titre Affichage -> Cl√© Originale pour chaque cat√©gorie ---
display_title_map_by_category = {}
for category, original_keys in visualizations_by_new_category.items():
    display_map = {"--- Choisir une visualisation ---": None} # Option par d√©faut
    for key in original_keys:
        display_map[create_display_title(key)] = key
    display_title_map_by_category[category] = display_map


# =============================================================================
# --- 7. MAIN APP LOGIC / PAGE CONTENT ---
# =============================================================================

current_choice = st.session_state.choix

# --- Introduction Section ---
if current_choice == "üëã Introduction":
    st.markdown("<h1 style='text-align: center; color: #5533FF;'>üëã Bienvenue sur notre projet de consommation d'√©lectricit√© en France ‚ö°</h1>", unsafe_allow_html=True)

    st.markdown(
        """
        <p style='text-align: center; font-size: 18px;'>
        La consommation d'√©lectricit√© est un enjeu majeur dans la transition √©nerg√©tique. Ce projet explore les donn√©es fran√ßaises afin de mieux comprendre les tendances de consommation,
        visualiser les variations saisonni√®res, et pr√©voir la demande √©nerg√©tique future. üå±
        </p>
        """,
        unsafe_allow_html=True
    )

    st.write("""
    üí° **Pourquoi ce projet ?**  
    L'√©nergie occupe une place centrale dans les d√©fis environnementaux et soci√©taux contemporains. La France, avec son mix √©nerg√©tique sp√©cifique, offre une opportunit√© unique d'explorer
    les dynamiques de production et de consommation, particuli√®rement marqu√©e par la pr√©dominance du nucl√©aire et la croissance des √©nergies renouvelables.  
    Ce projet vise √† r√©pondre aux enjeux strat√©giques suivants :
    - √âtudier l'√©volution temporelle de la consommation et production √©nerg√©tiques en France.
    - Mettre en relation ces tendances avec des facteurs cl√©s tels que la d√©mographie, les conditions climatiques, et les activit√©s √©conomiques.
    - D√©velopper des outils pr√©dictifs pour mieux anticiper les besoins √©nerg√©tiques et optimiser les ressources.
    """)

    st.write("""
    üîé **Objectifs du projet :**
    - Explorer les donn√©es de consommation d'√©lectricit√© en France
    - Cr√©er des visualisations interactives des tendances √©nerg√©tiques
    - Construire des mod√®les de machine learning bas√©s sur les donn√©es historiques
    - Fournir des insights utiles pour la gestion de la demande en √©lectricit√©
    """)

    if st.button("üöÄ Commencer l'exploration"):
        next_section = "üîé Exploration des donn√©es"
        st.session_state.choix = next_section
        st.rerun()

    # Affichage de l'image centr√©e avec encodage base64
        # <-- MODIFI√â : Chemin relatif -->
    image_path = "Visualisation/sunrise-3579931_1280.jpg"
    if os.path.exists(image_path):
        with open(image_path, "rb") as image_file:
            encoded = base64.b64encode(image_file.read()).decode()

        st.markdown(
            f"""
            <div style='display: flex; justify-content: center; margin-top: 30px;'>
                <img src="data:image/jpeg;base64,{encoded}" width="500"/>
            </div>
            <p style='text-align: center; font-size: 14px; color: gray;'>√ânergie renouvelable au lever du soleil üåÑ</p>
            """,
            unsafe_allow_html=True
        )
    else:
        st.warning("‚ùó L‚Äôimage n‚Äôa pas √©t√© trouv√©e √† l‚Äôemplacement sp√©cifi√© :")
        st.code(image_path)

# --- Data Exploration Section ---
elif current_choice == "üîé Exploration des donn√©es":
    st.markdown("<h1 style='text-align: left;'>üîé Exploration des Donn√©es</h1>", unsafe_allow_html=True)
    st.subheader("S√©lectionnez un dataset √† explorer")

    # --- Dictionnaire associant nom convivial et fonction getter ---
    dataset_options = {
        "üìÅ Consommation/Production d'√©l√©ctricit√© en France": get_eco2mix_data,
        "üè¢ Nombre d'Entreprises/√âtablissements": get_effectifs_data,
        "üå°Ô∏è Temp√©rature Quotidienne R√©gionale": get_temperature_data,
        "üë™ Population R√©gionale": get_population_data, # Nom clarifi√©
        "‚ö° Soutirages √©l√©ctrique r√©gionaux quotidiens": get_soutirage_data
    }
    dataset_names = list(dataset_options.keys())

    selected_dataset_name = st.selectbox(
        "Choisissez un dataset :",
        dataset_names,
        key="dataset_selector"
        # index=0 # Optionnel: pour s√©lectionner le premier par d√©faut
    )

    df_to_display = None
    if selected_dataset_name:
        getter_function = dataset_options[selected_dataset_name]
        # L'appel st.spinner est correct ici, car il est en dehors de la fonction cach√©e
        with st.spinner(f"Chargement et traitement des donn√©es '{selected_dataset_name}'..."):
            start_time = time.time()
            # Appel de la fonction getter qui g√®re le cache et le chargement interne
            df_to_display = getter_function() # Appelle _load_eco2mix_internal (nettoy√©e) si cache vide
            end_time = time.time()
            print(f"--- Time taken for getter '{selected_dataset_name}': {end_time - start_time:.4f} seconds ---")

    # --- Affichage conditionnel bas√© sur le dataset s√©lectionn√© ---
    # Ces appels st.warning/st.error sont corrects ici, car ils sont en dehors de la fonction cach√©e
    if df_to_display is not None:
        if df_to_display.empty:
             st.warning(f"Le dataset '{selected_dataset_name}' est vide ou n'a pas pu √™tre charg√©/trait√© correctement.")
             st.info("V√©rifiez si le fichier source existe, n'est pas vide et si les √©tapes de pr√©traitement n'ont pas supprim√© toutes les lignes.")
        else:
            # --- Affichage sp√©cifique pour Eco2mix ---
            # (Code inchang√© ici, car les st.* sont d√©j√† en dehors de la fonction cach√©e)
            if selected_dataset_name == "üìÅ Consommation/Production d'√©l√©ctricit√© en France":
                st.markdown("---")
                st.markdown(f"### üìù Aper√ßu: {selected_dataset_name}")
                st.write("Ce dataset contient des donn√©es (souvent horaires ou demi-horaires) sur la consommation, la production par fili√®re, et les √©changes inter-r√©gionaux/internationaux.")
                st.write(f"Nombre total de lignes: {len(df_to_display):,}".replace(",", " "))
                st.write("Affichage des 5 premi√®res lignes :")
                st.dataframe(df_to_display.head())

                st.markdown("---")
                st.markdown("### üìä Informations G√©n√©rales")
                st.write("Types de donn√©es des colonnes :")
                st.dataframe(df_to_display.dtypes.astype(str).reset_index().rename(columns={'index': 'Colonne', 0: 'Type'}))
                st.write("Statistiques descriptives (colonnes num√©riques) :")
                try:
                    st.dataframe(df_to_display.describe())
                except Exception as e:
                    st.warning(f"Impossible d'afficher les statistiques descriptives: {e}")


                st.markdown("---")
                st.markdown("### ‚ùì Analyse des valeurs manquantes")
                missing_values = df_to_display.isnull().sum()
                missing_df = missing_values[missing_values > 0].sort_values(ascending=False).reset_index()
                missing_df.columns = ['Colonne', 'Nombre Manquant']
                if not missing_df.empty:
                    st.write("Nombre de valeurs manquantes par colonne (colonnes avec > 0 manquants) :")
                    st.dataframe(missing_df)
                    total_missing = missing_df['Nombre Manquant'].sum()
                    total_cells = np.prod(df_to_display.shape)
                    percent_missing = (total_missing / total_cells) * 100 if total_cells > 0 else 0
                    st.write(f"Total des valeurs manquantes : {total_missing:,} ({percent_missing:.2f}% du total des cellules)".replace(",", " "))
                else:
                    st.success("‚úÖ Aucune valeur manquante d√©tect√©e dans ce dataset.")

                st.markdown("---")
                st.markdown("### üóìÔ∏è Consulter la consommation par r√©gion et date")
                # V√©rifier que les colonnes n√©cessaires existent ET ont le bon type
                required_cols = ['R√©gion', 'Date', 'Consommation (MW)']
                if all(col in df_to_display.columns for col in required_cols):
                     if pd.api.types.is_datetime64_any_dtype(df_to_display['Date']):
                         # S'assurer que Consommation est num√©rique (peut avoir √©t√© lue comme object)
                         if not pd.api.types.is_numeric_dtype(df_to_display['Consommation (MW)']):
                             df_to_display['Consommation (MW)'] = pd.to_numeric(df_to_display['Consommation (MW)'], errors='coerce')

                         regions = sorted(df_to_display['R√©gion'].dropna().unique())
                         if regions:
                             selected_region = st.selectbox("S√©lectionner une R√©gion:", regions, key="eco2mix_region_select")
                             # Utiliser les vraies min/max dates du DF pour le date_input
                             min_date = df_to_display['Date'].min().date()
                             max_date = df_to_display['Date'].max().date()
                             # Proposer la date la plus r√©cente par d√©faut
                             default_date = max_date if max_date >= min_date else min_date

                             selected_date_input = st.date_input(
                                 "S√©lectionner une Date:",
                                 min_value=min_date,
                                 max_value=max_date,
                                 value=default_date,
                                 key="eco2mix_date_select"
                             )
                             # Convertir la date s√©lectionn√©e en objet date pour la comparaison
                             selected_date = pd.to_datetime(selected_date_input).date()

                             # Filtrer le DataFrame
                             filtered_df_day = df_to_display[
                                 (df_to_display['R√©gion'] == selected_region) &
                                 (df_to_display['Date'].dt.date == selected_date)
                             ].copy() # Utiliser .copy() pour √©viter SettingWithCopyWarning

                             if filtered_df_day.empty:
                                 st.info(f"Aucune donn√©e de consommation trouv√©e pour '{selected_region}' le {selected_date_input.strftime('%d/%m/%Y')}.")
                                 total_consumption = 0
                             else:
                                 # Recalculer la somme sur le df filtr√© (la colonne devrait d√©j√† √™tre num√©rique)
                                 total_consumption = filtered_df_day['Consommation (MW)'].sum(skipna=True)

                             # Formater pour l'affichage
                             try:
                                 formatted_consumption = "{:,.0f}".format(total_consumption).replace(",", " ") if pd.notna(total_consumption) else "N/A"
                             except (ValueError, TypeError):
                                 formatted_consumption = "Erreur Format"

                             # Affichage am√©lior√©
                             st.markdown(f"""
                                        <div style='background-color: #262730; padding: 20px; border-radius: 10px; border: 1px solid #333; text-align: center; margin-top: 15px;'>
                                            <h4 style='font-weight: 500; color: #FAFAFA; margin-bottom: 12px;'>üí° Consommation Totale (Journali√®re)</h4>
                                            <p style='color: #AAA; font-size: 16px; margin-bottom: 8px;'>Pour <span style='color: #A0DAFF; font-weight: bold;'>{selected_region}</span> le <span style='color: #A0DAFF; font-weight: bold;'>{selected_date_input.strftime('%d/%m/%Y')}</span></p>
                                            <h2 style='color: #FFD700; font-weight: bold; letter-spacing: 1px;'>{formatted_consumption} MW</h2>
                                            <p style='font-size: 0.8em; color: #777; margin-top: 10px;'>(Somme des relev√©s disponibles pour ce jour)</p>
                                        </div>""", unsafe_allow_html=True)
                         else:
                            st.warning("Aucune r√©gion unique trouv√©e dans les donn√©es pour le filtrage.")
                     else:
                        st.error("La colonne 'Date' n'est pas au format datetime apr√®s chargement. V√©rifiez le fichier source ou la fonction de chargement.")
                else:
                    st.error(f"Colonnes requises ({', '.join(required_cols)}) manquantes pour cette analyse.")

            # --- Affichage sp√©cifique pour Effectifs ---
            elif selected_dataset_name == "üè¢ Nombre d'Entreprises/√âtablissements":
                # (Code inchang√© ici)
                st.markdown("---")
                st.markdown("### üìú Aper√ßu: Base √âtablissement par Tranche d'Effectif")
                st.write("""
                    Ce dataset recense le nombre d'√©tablissements par commune (identifi√©e par `CODGEO`, `LIBGEO`), ventil√© selon diff√©rentes tranches d'effectifs salari√©s.
                    Il donne une image de la structure √©conomique locale. Il inclut aussi les codes R√©gion (`REG`) et D√©partement (`DEP`).
                    Colonnes `E14TST`: Total, `E14TS0ND`: 0 salari√©s, `E14TS1`: 1-5, `E14TS6`: 6-9, etc.
                """)
                st.write(f"Nombre total de lignes (communes/entit√©s): {len(df_to_display):,}".replace(",", " "))
                st.write("Affichage des 5 premi√®res lignes :")
                st.dataframe(df_to_display.head())

                st.markdown("---")
                st.markdown("### üìä Informations G√©n√©rales")
                st.write("Types de donn√©es des colonnes :")
                st.dataframe(df_to_display.dtypes.astype(str).reset_index().rename(columns={'index': 'Colonne', 0: 'Type'}))
                st.write("Statistiques descriptives (colonnes num√©riques - nombre d'√©tablissements) :")
                try:
                    num_cols_effectifs_present = [col for col in ['E14TST', 'E14TS0ND', 'E14TS1', 'E14TS6', 'E14TS10', 'E14TS20', 'E14TS50', 'E14TS100', 'E14TS200', 'E14TS500'] if col in df_to_display.columns]
                    if num_cols_effectifs_present:
                        st.dataframe(df_to_display[num_cols_effectifs_present].describe())
                    else:
                        st.warning("Aucune colonne d'effectif num√©rique standard trouv√©e pour les statistiques.")
                except Exception as e:
                    st.warning(f"Impossible d'afficher les statistiques descriptives: {e}")


                st.markdown("---")
                st.markdown("### ‚ùì Analyse des valeurs manquantes")
                missing_values = df_to_display.isnull().sum()
                missing_df = missing_values[missing_values > 0].sort_values(ascending=False).reset_index()
                missing_df.columns = ['Colonne', 'Nombre Manquant']
                if not missing_df.empty:
                    st.write("Nombre de valeurs manquantes par colonne (apr√®s conversion num√©rique) :")
                    st.dataframe(missing_df)
                else:
                    st.success("‚úÖ Aucune valeur manquante d√©tect√©e dans ce dataset apr√®s traitement initial.")

                st.markdown("---")
                st.markdown("### üìç Consulter les effectifs agr√©g√©s par D√©partement")
                effectifs_req_cols = ['DEP', 'LIBGEO'] # Minimal pour le filtre/libell√©
                num_cols_effectifs = ['E14TST', 'E14TS0ND', 'E14TS1', 'E14TS6', 'E14TS10', 'E14TS20', 'E14TS50', 'E14TS100', 'E14TS200', 'E14TS500']
                # V√©rifier que DEP et LIBGEO existent
                if all(col in df_to_display.columns for col in effectifs_req_cols):
                     # S'assurer que DEP est bien de type string pour le filtrage et l'affichage correct
                     if not pd.api.types.is_string_dtype(df_to_display['DEP']):
                         st.warning("La colonne 'DEP' n'est pas de type string. Tentative de correction pour le filtre...")
                         # Appliquer la m√™me logique de correction que dans le loader au cas o√π
                         try:
                             df_to_display['DEP'] = df_to_display['DEP'].fillna('NA').astype(str).str.replace(r'\.0$', '', regex=True)
                             df_to_display['DEP'] = df_to_display['DEP'].apply(lambda x: x.zfill(2) if x != 'NA' and x.isdigit() else x)
                             df_to_display['DEP'] = df_to_display['DEP'].replace('NA', pd.NA) # Remettre NA si c'√©tait NaN
                         except Exception as e_conv_filter:
                             st.error(f"Erreur lors de la tentative de correction de la colonne DEP: {e_conv_filter}. Le filtre risque de ne pas fonctionner.")
                             st.stop() # Arr√™ter si la colonne cl√© n'est pas utilisable

                     # Obtenir la liste unique des d√©partements valides (ignorer les NA)
                     deps = sorted(df_to_display['DEP'].dropna().unique())

                     if deps:
                         # Cr√©er un mapping pour afficher "Code - Nom Exemple" dans le selectbox
                         # Trouver une commune repr√©sentative (ex: la plus grande E14TST) pour chaque DEP
                         dep_labels = {}
                         if 'E14TST' in df_to_display.columns and pd.api.types.is_numeric_dtype(df_to_display['E14TST']):
                              try:
                                # idx = df_to_display.groupby('DEP')['E14TST'].idxmax() # Peut √©chouer si NaN ou empty groups
                                # representative_communes = df_to_display.loc[idx][['DEP', 'LIBGEO']].set_index('DEP')['LIBGEO']
                                # M√©thode plus s√ªre: it√©rer sur les deps uniques
                                for d in deps:
                                     communes_in_dep = df_to_display[df_to_display['DEP'] == d]
                                     if not communes_in_dep.empty:
                                         # Prendre la premi√®re commune par ordre alphab√©tique comme exemple
                                         # Ou celle avec le plus d'√©tablissements si E14TST est fiable
                                         # best_commune = communes_in_dep.loc[communes_in_dep['E14TST'].idxmax()]['LIBGEO'] if not communes_in_dep['E14TST'].isnull().all() else communes_in_dep.iloc[0]['LIBGEO']
                                         best_commune = communes_in_dep.sort_values(by='LIBGEO').iloc[0]['LIBGEO']
                                         dep_labels[d] = f"{d} - (Ex: {best_commune})"
                                     else:
                                         dep_labels[d] = f"{d} - (N/A)"

                              except Exception as e_repr:
                                  print(f"Warning: Could not generate representative commune names: {e_repr}")
                                  # Fallback: juste afficher le code
                                  dep_labels = {d: d for d in deps}
                         else:
                             # Fallback si E14TST n'existe pas ou n'est pas num√©rique
                             print("Warning: Column E14TST not suitable for finding representative communes. Using first commune found.")
                             for d in deps:
                                 first_commune = df_to_display[df_to_display['DEP'] == d].iloc[0]['LIBGEO'] if not df_to_display[df_to_display['DEP'] == d].empty else "N/A"
                                 dep_labels[d] = f"{d} - (Ex: {first_commune})"


                         selected_dep_code = st.selectbox(
                             "S√©lectionner un D√©partement:",
                             options=deps,
                             format_func=lambda x: dep_labels.get(x, x), # Afficher "Code - Ex: Nom"
                             key="effectifs_dep_select",
                             index=0 # S√©lectionner le premier par d√©faut
                         )

                         if selected_dep_code:
                             # Filtrer les donn√©es pour le d√©partement choisi
                             filtered_dep_df = df_to_display[df_to_display['DEP'] == selected_dep_code].copy()

                             if not filtered_dep_df.empty:
                                 # Calculer les totaux pour les colonnes num√©riques existantes dans ce d√©partement
                                 sums = {}
                                 for col in num_cols_effectifs:
                                     if col in filtered_dep_df.columns and pd.api.types.is_numeric_dtype(filtered_dep_df[col]):
                                         # Assurer la somme sur des num√©riques, ignorer NaN
                                         sums[col] = filtered_dep_df[col].sum(skipna=True)
                                     else:
                                         sums[col] = 0 # Mettre 0 si la colonne manque ou n'est pas num√©rique

                                 # Afficher les m√©triques r√©sum√©es
                                 st.markdown(f"""
                                     <div style='background-color: #262730; padding: 20px; border-radius: 10px; border: 1px solid #333; margin-top: 15px;'>
                                         <h4 style='font-weight: 500; color: #FAFAFA; text-align: center; margin-bottom: 15px;'>üè¢ Structure des √âtablissements (Agr√©g√©e)</h4>
                                         <p style='color: #AAA; font-size: 16px; text-align: center; margin-bottom: 15px;'>
                                             Pour le d√©partement <span style='color: #A0DAFF; font-weight: bold;'>{dep_labels.get(selected_dep_code, selected_dep_code)}</span>
                                         </p>
                                         <div style='display: flex; justify-content: space-around; text-align: center; flex-wrap: wrap;'>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #FFF; font-size:0.9em; margin-bottom: 5px;'>Total √âtab.</p>
                                                 <h3 style='color: #FFD700; margin-top: 0;'>{sums.get('E14TST', 0):,.0f}</h3>
                                             </div>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>0 salari√©s</p>
                                                 <h3 style='color: #ADD8E6; margin-top: 0;'>{sums.get('E14TS0ND', 0):,.0f}</h3>
                                             </div>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>1-5</p>
                                                 <h3 style='color: #90EE90; margin-top: 0;'>{sums.get('E14TS1', 0):,.0f}</h3>
                                             </div>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>6-9</p>
                                                 <h3 style='color: #FFB6C1; margin-top: 0;'>{sums.get('E14TS6', 0):,.0f}</h3>
                                             </div>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>10-19</p>
                                                 <h3 style='color: #FFA07A; margin-top: 0;'>{sums.get('E14TS10', 0):,.0f}</h3>
                                             </div>
                                              <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>20-49</p>
                                                 <h3 style='color: #B19CD9; margin-top: 0;'>{sums.get('E14TS20', 0):,.0f}</h3>
                                             </div>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>50-99</p>
                                                 <h3 style='color: #FFDB58; margin-top: 0;'>{sums.get('E14TS50', 0):,.0f}</h3>
                                             </div>
                                             <div style='margin: 5px 10px;'>
                                                 <p style='color: #AAA; font-size:0.9em; margin-bottom: 5px;'>100-199</p>
                                                 <h3 style='color: #F0E68C; margin-top: 0;'>{sums.get('E14TS100', 0):,.0f}</h3>
                                             </div>
                                             # Ajouter E14TS200 et E14TS500 si pertinent
                                         </div>
                                     </div>
                                 """, unsafe_allow_html=True)

                                 # Ajouter un graphique √† barres pour la distribution des tranches
                                 st.markdown("---")
                                 st.write("R√©partition par tranche d'effectif (Nombre total d'√©tablissements dans le d√©partement) :")
                                 tranche_labels_map = {
                                     '0 salari√©s': 'E14TS0ND', '1-5': 'E14TS1', '6-9': 'E14TS6',
                                     '10-19': 'E14TS10', '20-49': 'E14TS20', '50-99': 'E14TS50',
                                     '100-199': 'E14TS100', '200-499': 'E14TS200', '500+': 'E14TS500'
                                 }
                                 # Utiliser les sommes d√©j√† calcul√©es (sums) en filtrant sur les colonnes existantes
                                 tranche_sums_chart = {}
                                 for label, col_name in tranche_labels_map.items():
                                     if col_name in sums: # Utilise les sommes d√©j√† calcul√©es et valid√©es
                                         tranche_sums_chart[label] = sums[col_name]

                                 if tranche_sums_chart:
                                     # Cr√©er une Series pour le graphique
                                     tranche_sums_series = pd.Series(tranche_sums_chart)
                                     st.bar_chart(tranche_sums_series)
                                 else:
                                     st.warning("Aucune donn√©e de tranche d'effectif valide √† afficher pour ce d√©partement.")

                             else:
                                 st.info(f"Aucune donn√©e d'effectif trouv√©e pour le d√©partement {selected_dep_code}.")
                     else:
                         st.warning("Aucun code d√©partement valide trouv√© dans les donn√©es pour permettre le filtrage.")
                else:
                     st.error(f"Colonnes requises ('DEP', 'LIBGEO') manquantes pour le filtre des effectifs par d√©partement.")


            # --- Affichage sp√©cifique pour Soutirage ---
            elif selected_dataset_name == "‚ö° Soutirages √©l√©ctrique r√©gionaux quotidiens":
                # (Code inchang√© ici)
                st.markdown("---")
                st.markdown(f"### üìù Aper√ßu: {selected_dataset_name}")
                st.write("Ce dataset fournit les volumes d'√©nergie √©lectrique 'soutir√©s' (consomm√©s) du r√©seau, agr√©g√©s par jour et par r√©gion.")
                st.write(f"Nombre total de lignes: {len(df_to_display):,}".replace(",", " "))
                st.write("Affichage des 5 premi√®res lignes :")
                st.dataframe(df_to_display.head())

                st.markdown("---")
                st.markdown("### üìä Informations G√©n√©rales")
                st.write("Types de donn√©es des colonnes :")
                st.dataframe(df_to_display.dtypes.astype(str).reset_index().rename(columns={'index': 'Colonne', 0: 'Type'}))
                st.write("Statistiques descriptives (colonnes num√©riques) :")
                try:
                    st.dataframe(df_to_display.describe())
                except Exception as e:
                    st.warning(f"Impossible d'afficher les statistiques descriptives: {e}")


                st.markdown("---")
                st.markdown("### ‚ùì Analyse des valeurs manquantes")
                missing_values = df_to_display.isnull().sum()
                missing_df = missing_values[missing_values > 0].sort_values(ascending=False).reset_index()
                missing_df.columns = ['Colonne', 'Nombre Manquant']
                if not missing_df.empty:
                     st.write("Nombre de valeurs manquantes par colonne:")
                     st.dataframe(missing_df)
                else:
                     st.success("‚úÖ Aucune valeur manquante d√©tect√©e.")
                # Ajouter ici une section de filtrage/visualisation si pertinent (similaire √† Eco2mix/Temp)


            # --- Affichage sp√©cifique pour Temp√©rature ---
            elif selected_dataset_name == "üå°Ô∏è Temp√©rature Quotidienne R√©gionale":
                # (Code inchang√© ici)
                st.markdown("---")
                st.markdown("### üìú Aper√ßu: Temp√©rature Quotidienne R√©gionale")
                st.write("""
                    Ce dataset contient des relev√©s m√©t√©orologiques quotidiens par r√©gion (TMin, TMax, TMoy).
                    Essentiel pour corr√©ler la m√©t√©o et la consommation d'√©nergie.
                """)
                st.write(f"Nombre total de lignes: {len(df_to_display):,}".replace(",", " "))
                st.write("Affichage des 5 premi√®res lignes :")
                cols_to_show_temp = ['Date', 'R√©gion', 'TMin (¬∞C)', 'TMax (¬∞C)', 'TMoy (¬∞C)']
                st.dataframe(df_to_display[[col for col in cols_to_show_temp if col in df_to_display.columns]].head())

                st.markdown("---")
                st.markdown("### üìä Informations G√©n√©rales")
                st.write("Types de donn√©es des colonnes :")
                st.dataframe(df_to_display.dtypes.astype(str).reset_index().rename(columns={'index': 'Colonne', 0: 'Type'}))
                st.write("Statistiques descriptives (colonnes num√©riques) :")
                try:
                    temp_num_cols = ['TMin (¬∞C)', 'TMax (¬∞C)', 'TMoy (¬∞C)']
                    st.dataframe(df_to_display[[col for col in temp_num_cols if col in df_to_display.columns]].describe())
                except Exception as e:
                    st.warning(f"Impossible d'afficher les statistiques descriptives: {e}")


                st.markdown("---")
                st.markdown("### ‚ùì Analyse des valeurs manquantes")
                missing_values = df_to_display.isnull().sum()
                missing_df = missing_values[missing_values > 0].sort_values(ascending=False).reset_index()
                missing_df.columns = ['Colonne', 'Nombre Manquant']
                if not missing_df.empty:
                    st.write("Nombre de valeurs manquantes par colonne:")
                    st.dataframe(missing_df)
                else:
                    st.success("‚úÖ Aucune valeur manquante d√©tect√©e.")

                st.markdown("---")
                st.markdown("### üå°Ô∏è Consulter la temp√©rature par r√©gion et date")
                temp_req_cols = ['R√©gion', 'Date', 'TMin (¬∞C)', 'TMax (¬∞C)', 'TMoy (¬∞C)']
                if all(col in df_to_display.columns for col in temp_req_cols):
                    if pd.api.types.is_datetime64_any_dtype(df_to_display['Date']):
                         # V√©rifier que les colonnes de temp√©rature sont num√©riques
                         for col in ['TMin (¬∞C)', 'TMax (¬∞C)', 'TMoy (¬∞C)']:
                             if not pd.api.types.is_numeric_dtype(df_to_display[col]):
                                 df_to_display[col] = pd.to_numeric(df_to_display[col], errors='coerce')

                         regions_temp = sorted(df_to_display['R√©gion'].dropna().unique())
                         if regions_temp:
                            selected_region_temp = st.selectbox("S√©lectionner une R√©gion:", regions_temp, key="temp_region_select")
                            min_date_temp = df_to_display['Date'].min().date()
                            max_date_temp = df_to_display['Date'].max().date()
                            default_date_temp = max_date_temp if max_date_temp >= min_date_temp else min_date_temp
                            selected_date_temp_input = st.date_input(
                                "S√©lectionner une Date:",
                                min_value=min_date_temp,
                                max_value=max_date_temp,
                                value=default_date_temp,
                                key="temp_date_select"
                            )
                            selected_date_temp = pd.to_datetime(selected_date_temp_input).date()

                            # Filtrer les donn√©es
                            filtered_temp_day = df_to_display[
                                (df_to_display['R√©gion'] == selected_region_temp) &
                                (df_to_display['Date'].dt.date == selected_date_temp)
                            ]

                            if not filtered_temp_day.empty:
                                # Il peut y avoir plusieurs enregistrements pour une m√™me date/r√©gion? Prendre le premier.
                                temp_data = filtered_temp_day.iloc[0]
                                # Utiliser .get() pour la robustesse si une colonne manque malgr√© le check initial
                                tmin = temp_data.get('TMin (¬∞C)', np.nan)
                                tmax = temp_data.get('TMax (¬∞C)', np.nan)
                                tmoy = temp_data.get('TMoy (¬∞C)', np.nan)
                                # Formater pour affichage, g√©rer les NaN
                                tmin_str = f"{tmin:.1f}¬∞C" if pd.notna(tmin) else "N/A"
                                tmax_str = f"{tmax:.1f}¬∞C" if pd.notna(tmax) else "N/A"
                                tmoy_str = f"{tmoy:.1f}¬∞C" if pd.notna(tmoy) else "N/A"

                                st.markdown(f"""
                                    <div style='background-color: #262730; padding: 20px; border-radius: 10px; border: 1px solid #333; margin-top: 15px;'>
                                        <h4 style='font-weight: 500; color: #FAFAFA; text-align: center; margin-bottom: 15px;'>üå°Ô∏è Temp√©ratures Enregistr√©es</h4>
                                        <p style='color: #AAA; font-size: 16px; text-align: center; margin-bottom: 15px;'>Pour <span style='color: #A0DAFF; font-weight: bold;'>{selected_region_temp}</span> le <span style='color: #A0DAFF; font-weight: bold;'>{selected_date_temp_input.strftime('%d/%m/%Y')}</span></p>
                                        <div style='display: flex; justify-content: space-around; text-align: center; flex-wrap: wrap;'>
                                            <div style='margin: 5px 10px;'><p style='color: #ADD8E6; margin-bottom: 5px; font-size:0.9em;'>Minimale</p><h3 style='color: #87CEEB; margin-top: 0;'>{tmin_str}</h3></div>
                                            <div style='margin: 5px 10px;'><p style='color: #FFD700; margin-bottom: 5px; font-size:0.9em;'>Moyenne</p><h3 style='color: #FFFFE0; margin-top: 0;'>{tmoy_str}</h3></div>
                                            <div style='margin: 5px 10px;'><p style='color: #FFB6C1; margin-bottom: 5px; font-size:0.9em;'>Maximale</p><h3 style='color: #FFA07A; margin-top: 0;'>{tmax_str}</h3></div>
                                        </div>
                                    </div>""", unsafe_allow_html=True)
                            else:
                                st.info(f"Aucune donn√©e de temp√©rature trouv√©e pour '{selected_region_temp}' le {selected_date_temp_input.strftime('%d/%m/%Y')}.")
                         else:
                            st.warning("Aucune r√©gion unique trouv√©e pour le filtrage temp√©rature.")
                    else:
                        st.error("La colonne 'Date' n'est pas au format datetime apr√®s chargement (Temp√©rature).")
                else:
                    st.error(f"Colonnes requises ({', '.join(temp_req_cols)}) manquantes pour le filtre temp√©rature.")


            # --- Affichage sp√©cifique pour Population ---
            elif selected_dataset_name == "üë™ Population R√©gionale":
                # (Code inchang√© ici)
                st.markdown("---")
                st.markdown(f"### üìù Aper√ßu: {selected_dataset_name}")
                st.write("Donn√©es de population par r√©gion (source INSEE), transform√©es au format 'long' (une ligne par r√©gion par date/ann√©e).")
                st.write(f"Nombre total de lignes: {len(df_to_display):,}".replace(",", " "))
                st.write("Affichage des 5 premi√®res lignes (apr√®s transformation) :")
                st.dataframe(df_to_display.head())

                st.markdown("---")
                st.markdown("### üìä Informations G√©n√©rales")
                st.write("Types de donn√©es des colonnes :")
                st.dataframe(df_to_display.dtypes.astype(str).reset_index().rename(columns={'index': 'Colonne', 0: 'Type'}))
                st.write("Statistiques descriptives (Population) :")
                try:
                    if 'Population' in df_to_display.columns:
                         st.dataframe(df_to_display[['Population']].describe())
                    else:
                         st.warning("Colonne 'Population' non trouv√©e pour les statistiques.")
                except Exception as e:
                    st.warning(f"Impossible d'afficher les statistiques descriptives: {e}")

                st.markdown("---")
                st.markdown("### ‚ùì Analyse des valeurs manquantes (apr√®s transformation)")
                missing_values = df_to_display.isnull().sum()
                missing_df = missing_values[missing_values > 0].sort_values(ascending=False).reset_index()
                missing_df.columns = ['Colonne', 'Nombre Manquant']
                if not missing_df.empty:
                     st.write("Nombre de valeurs manquantes par colonne :")
                     st.dataframe(missing_df)
                else:
                     st.success("‚úÖ Aucune valeur manquante d√©tect√©e apr√®s traitement.")

                st.markdown("---")
                st.markdown("### üë™ Consulter la population par r√©gion et ann√©e")
                pop_req_cols = ['R√©gion', 'Date', 'Population']
                if all(col in df_to_display.columns for col in pop_req_cols):
                    if pd.api.types.is_datetime64_any_dtype(df_to_display['Date']):
                        if not pd.api.types.is_numeric_dtype(df_to_display['Population']):
                            df_to_display['Population'] = pd.to_numeric(df_to_display['Population'], errors='coerce')

                        regions_pop = sorted(df_to_display['R√©gion'].dropna().unique())
                        # Les donn√©es de pop sont souvent annuelles, extraire les ann√©es uniques
                        years_pop = sorted(df_to_display['Date'].dt.year.dropna().unique())

                        if regions_pop and years_pop:
                            selected_region_pop = st.selectbox("S√©lectionner une R√©gion:", regions_pop, key="pop_region_select")
                            selected_year_pop = st.selectbox("S√©lectionner une Ann√©e:", years_pop, key="pop_year_select")

                            # Filtrer par r√©gion ET ann√©e
                            filtered_pop = df_to_display[
                                (df_to_display['R√©gion'] == selected_region_pop) &
                                (df_to_display['Date'].dt.year == selected_year_pop)
                            ].copy()

                            population_value = np.nan
                            date_display = f"l'ann√©e {selected_year_pop}" # Default display

                            if not filtered_pop.empty:
                                # S'il y a plusieurs entr√©es pour l'ann√©e (peu probable mais possible), prendre la premi√®re/derni√®re ? Prendre la premi√®re.
                                population_value = filtered_pop['Population'].iloc[0]
                                # Tenter d'afficher la date exacte si disponible
                                date_exact = filtered_pop['Date'].iloc[0]
                                if pd.notna(date_exact):
                                    date_display = date_exact.strftime('%d/%m/%Y')
                            else:
                                population_value = 0 # Ou laisser NaN/afficher "Non trouv√©e"

                            # Formater la population
                            if pd.notna(population_value):
                                try:
                                    formatted_population = "{:,.0f}".format(population_value).replace(",", " ")
                                except (ValueError, TypeError): formatted_population = "Erreur Format"
                            else:
                                formatted_population = "Donn√©e non trouv√©e"


                            st.markdown(f"""
                                <div style='background-color: #262730; padding: 20px; border-radius: 10px; border: 1px solid #333; text-align: center; margin-top: 15px;'>
                                    <h4 style='font-weight: 500; color: #FAFAFA; margin-bottom: 12px;'>üë• Population Estim√©e (Source: INSEE)</h4>
                                     <p style='color: #AAA; font-size: 16px; margin-bottom: 8px;'>Pour <span style='color: #A0DAFF; font-weight: bold;'>{selected_region_pop}</span> pour <span style='color: #A0DAFF; font-weight: bold;'>{date_display}</span></p>
                                    <h2 style='color: #90EE90; font-weight: bold; letter-spacing: 1px;'>{formatted_population} habitants</h2>
                                </div>""", unsafe_allow_html=True)
                        else:
                            st.warning("Impossible d'extraire les r√©gions ou les ann√©es uniques pour le filtre population.")
                    else:
                        st.error("La colonne 'Date' n'est pas au format datetime apr√®s chargement (Population).")
                else:
                    st.error(f"Colonnes requises ({', '.join(pop_req_cols)}) manquantes pour cette analyse (Population).")

    elif selected_dataset_name:
        # Ce cas est atteint si df_to_display est None (erreur de chargement retourn√©e par le getter)
        st.error(f"Le chargement ou le traitement initial du dataset '{selected_dataset_name}' a √©chou√©.")
        st.info("Veuillez v√©rifier le chemin d'acc√®s au fichier, son format (CSV avec s√©parateur attendu , ou ;), son encodage (UTF-8 ou Latin-1), et consultez les messages d'erreur d√©taill√©s dans la console pour plus d'indices.")
        # Afficher l'erreur traceback si disponible (utile pour le d√©bogage)
        # Note: En production, on pourrait vouloir masquer traceback.
        # V√©rifier si une exception a √©t√© captur√©e (vous pourriez la stocker dans session_state si n√©cessaire)
        # Si traceback n'est pas directement disponible ici, le message d'erreur de la console est la meilleure piste.
        # st.code(traceback.format_exc()) # Cette ligne ne fonctionnera que si l'exception est lev√©e ici.


# --- Data Visualisation Section ---
elif current_choice == "üìä Data Visualisation":
    section_display_name = SECTION_ICONS.get(current_choice, current_choice)
    st.markdown(f"<h1 style='text-align: left;'>{section_display_name}</h1>", unsafe_allow_html=True)
    st.write("Explorez les diff√©rentes visualisations organis√©es par th√®me.")
    st.markdown("---")

    # /!\ MODIFICATION : Utilise la liste NEW_CATEGORIES_ORDERED mise √† jour (sans Analyses R√©gionales)
    # Cr√©er les onglets pour les nouvelles cat√©gories
    tabs = st.tabs(NEW_CATEGORIES_ORDERED)

    # Parcourir chaque cat√©gorie (onglet) et afficher le contenu correspondant
    for i, category_name in enumerate(NEW_CATEGORIES_ORDERED):
        with tabs[i]:
            st.subheader(f"Visualisations : {category_name}")

            # R√©cup√©rer le mapping titre affichage -> cl√© originale pour cette cat√©gorie
            # Ce mapping a √©t√© mis √† jour par la logique de regroupement pr√©c√©dente
            current_display_map = display_title_map_by_category.get(category_name, {})
            display_titles_options = list(current_display_map.keys())

            if len(display_titles_options) > 1: # V√©rifier s'il y a des visualisations (plus que juste "--- Choisir ---")
                # Menu d√©roulant pour s√©lectionner une visualisation dans cet onglet
                selected_display_title = st.selectbox(
                    f"Choisissez une visualisation pour '{category_name}':",
                    options=display_titles_options,
                    key=f"visu_select_{i}", # Cl√© unique pour chaque selectbox
                    index=0 # S√©lectionner "--- Choisir ---" par d√©faut
                )

                # R√©cup√©rer la cl√© originale correspondante
                original_key = current_display_map.get(selected_display_title)

                # --- Affichage de l'image et du texte si une visualisation est choisie ---
                if original_key:
                    try:
                        visu_number = original_key.split('.')[0]
                        image_filename = f"{visu_number}.png"
                        # Adapter le chemin si vos images sont ailleurs
                        image_path = os.path.join('Visualisation', image_filename)

                        st.markdown("---") # S√©parateur avant la visualisation

                        # Colonnes pour l'image et le texte (optionnel, pour la mise en page)
                        col1, col2 = st.columns([1, 1]) # Version (Image 1/2, Texte 1/2)

                        with col1:
                            if os.path.exists(image_path):
                                st.image(image_path, caption=f"Visualisation : {original_key}")
                            else:
                                st.warning(f"Image non trouv√©e : {image_path}")
                                st.info(f"Assurez-vous que l'image '{image_filename}' existe dans le dossier 'Visualisation'.")

                        with col2:
                            description = visualizations_data[original_key]["text"]
                            st.markdown(f"#### Analyse")
                            st.write(description) # Le texte s'√©talera maintenant dans une colonne plus large

                    except Exception as e:
                        st.error(f"Erreur lors de l'affichage de la visualisation '{original_key}': {e}")
                        if 'image_path' in locals(): # V√©rifie si image_path a √©t√© d√©fini
                             st.error(f"Chemin de l'image tent√© : {image_path}")

                elif selected_display_title != "--- Choisir une visualisation ---":
                    st.warning("Erreur : impossible de trouver la cl√© originale pour le titre s√©lectionn√©.")

            else:
                st.info(f"Aucune visualisation disponible pour la cat√©gorie '{category_name}' pour le moment.")


# --- Section Mod√©lisation ---
elif current_choice == "‚öôÔ∏è Mod√©lisation":
    section_display_name = SECTION_ICONS.get(current_choice, current_choice)
    st.markdown(f"<h1 style='text-align: left;'>{section_display_name}</h1>", unsafe_allow_html=True)
    df_final_preview = pd.DataFrame() # Initialisation pour √©viter les erreurs si le chargement √©choue

    # --- Contenu pour la section Preprocessing (dans un expander ferm√© par d√©faut) ---
    # /!\ MODIFICATION: expanded=False /!\
    with st.expander("üõ†Ô∏è Preprocessing des Donn√©es üõ†Ô∏è", expanded=False):

        st.markdown(
    "<h2 style='color: #5533FF; text-align: center;'>üõ†Ô∏è Preprocessing des Donn√©es üõ†Ô∏è</h2>",
    unsafe_allow_html=True
) # <-- Parenth√®se fermante ajout√©e ici

        # Texte d'introduction
        st.write("""
        Avant de pouvoir entra√Æner nos mod√®les de Machine Learning, nous avons effectu√© un preprocessing minutieux des donn√©es. Cette √©tape cruciale garantit la qualit√© et la coh√©rence des donn√©es utilis√©es pour l'entra√Ænement.
        """)

        # Section des jeux de donn√©es sources
        st.subheader("Afficher les jeux de donn√©es sources üìÅ")
        st.markdown("""
        *   **eco2mix-regional-cons-def.csv** : Consommation √©nerg√©tique r√©gionale par type de source.
        *   **temperature-quotidienne-regionale.csv** : Temp√©ratures moyennes quotidiennes par r√©gion.
        *   **soutirages-regionaux-quotidiens-consolides-rpt.csv** : Consommation sectorielle r√©gionale consolid√©e.
        *   **population - insee.csv** : Population r√©gionale annuelle.
        *   **base_etablissement_par_tranche_effectif.csv** : Nombre d'entreprises par r√©gion.
        """)

        # Section des √©tapes cl√©s du preprocessing
        st.markdown("<h3 style='color: #B19CD9;'>√âtapes cl√©s du preprocessing üõ†Ô∏è‚öôÔ∏è</h3>", unsafe_allow_html=True)

        # --- √âtape 1 ---
        st.markdown("1.  **Conversion et Nettoyage des Donn√©es**")
        st.markdown("""
        *   Conversion des colonnes de dates au format `datetime`.
        *   Suppression des colonnes redondantes ou non pertinentes (ex: 'Code INSEE r√©gion', 'Heure').
        """)

        # --- √âtape 2 ---
        st.markdown("2.  **Cr√©ation de Colonnes D√©riv√©es et Agr√©grations**")
        st.markdown("""
        *   Cr√©ation de colonnes pour le jour, le mois et l'ann√©e √† partir de la colonne date.
        *   Agr√©gation des donn√©es par jour et par r√©gion (moyennes, sommes).
        """)

        # --- √âtape 3 ---
        st.markdown("3.  **Gestion des Valeurs Manquantes**")
        st.markdown("*   Remplacement des valeurs manquantes de temp√©rature par la temp√©rature moyenne mensuelle de la r√©gion concern√©e.")
        st.markdown("**D√©tails sur la gestion des valeurs manquantes** üîç")
        st.markdown("*   Calcul de la temp√©rature moyenne mensuelle par r√©gion.")
        st.markdown("*   Imputation des valeurs manquantes avec ces moyennes.")

        # --- √âtape 4 ---
        st.markdown("4.  **Retraitement des Donn√©es Socio-√âconomiques**")
        st.markdown("*   Harmonisation des noms de r√©gions.")
        st.markdown("*   Cr√©ation d'une plage de dates compl√®te pour les donn√©es de population.")

        # --- √âtape 5 ---
        st.markdown("5.  **Harmonisation des Plages de Dates et Fusion des DataFrames**")
        st.markdown("*   Filtrage des donn√©es pour ne conserver que la p√©riode du 1er janvier 2019 au 31 janvier 2023.")
        st.markdown("*   Fusion des diff√©rents DataFrames en un seul DataFrame final, `df_final`, en utilisant la r√©gion et la date comme cl√©s de jointure.")

        # --- Aper√ßu du DataFrame Final ---
        st.markdown("### Aper√ßu du DataFrame final (df_final)") # Utilisation de H3

        df_final_path = DF_FINAL_CSV_PATH
        try:
            # Essayer de lire avec sep=',' (comme dans l'exemple)
            df_final_preview = pd.read_csv(df_final_path, sep=',')
            st.dataframe(df_final_preview.head())
            print(f"--- df_final loaded successfully with sep=',' from {df_final_path}")
        except FileNotFoundError:
            st.error(f"Erreur : Le fichier du DataFrame final n'a pas √©t√© trouv√© √† l'emplacement : {df_final_path}")
            st.info(f"Assurez-vous que le fichier '{os.path.basename(df_final_path)}' existe dans le r√©pertoire '{os.path.dirname(df_final_path)}'.")
            print(f"Error: df_final file not found at {df_final_path}")
            df_final_preview = pd.DataFrame()
        except Exception as e_comma:
            print(f"Warning: Failed reading df_final with sep=',': {e_comma}. Trying sep=';'...")
            # st.warning(f"√âchec lecture df_final avec sep=',': {e_comma}. Essai avec sep=';'...")
            try:
                # Essayer avec sep=';' comme fallback
                df_final_preview = pd.read_csv(df_final_path, sep=';')
                st.dataframe(df_final_preview.head())
                print(f"--- df_final loaded successfully with sep=';' from {df_final_path}")
            except Exception as e_semi:
                 st.error(f"Une erreur est survenue lors du chargement ou de l'affichage du DataFrame final (avec sep=',' et sep=';') : {e_semi}")
                 st.warning(f"V√©rifiez le format du fichier CSV ({df_final_path}), son s√©parateur et son encodage.")
                 print(f"Error: Failed reading df_final with both sep=',' and sep=';': {e_semi}")
                 traceback.print_exc()
                 df_final_preview = pd.DataFrame()

        # --- Matrice de Corr√©lation (reste √† l'int√©rieur de l'expander) ---
        st.subheader("üìä Matrice de Corr√©lation")

        if os.path.exists(CORRELATION_MATRIX_IMAGE_PATH):
            col_img_left, col_img_center, col_img_right = st.columns([1, 2, 1])
            with col_img_center:
                st.image(CORRELATION_MATRIX_IMAGE_PATH, caption="Visualisation de la Matrice de Corr√©lation")
        else:
            st.warning(f"Image de la matrice de corr√©lation non trouv√©e : {CORRELATION_MATRIX_IMAGE_PATH}")
            st.info(f"Assurez-vous que le fichier '{os.path.basename(CORRELATION_MATRIX_IMAGE_PATH)}' existe dans le dossier '{os.path.dirname(CORRELATION_MATRIX_IMAGE_PATH)}'.")
            print(f"Warning: Correlation matrix image not found: {CORRELATION_MATRIX_IMAGE_PATH}")

        st.write("""
        **Conclusion :** La matrice de corr√©lation confirme l'importance des variables choisies pour la mod√©lisation et met en √©vidence les relations attendues entre consommation √©nerg√©tique, temp√©rature et secteurs d'activit√©.
        """)

    # --- /!\ MODIFICATION : Expander pour la partie MODELISATION ferm√© par d√©faut /!\ ---
    # /!\ MODIFICATION: expanded=False /!\
    with st.expander("ü§ñ Mod√®le de Machine Learning ü§ñ", expanded=False): # <-- Expander ferm√© par d√©faut
        # Le titre H2 est maintenant redondant avec le titre de l'expander, nous le supprimons.
        # st.markdown("<h2 style='text-align: center; color: #5533FF;'>ü§ñ Mod√®le de Machine Learning ü§ñ</h2>", unsafe_allow_html=True)

        st.markdown(
    "<h2 style='color: #5533FF; text-align: center;'>ü§ñ Mod√®le de Machine Learning ü§ñ</h2>",
    unsafe_allow_html=True
)

        st.markdown("""
        Apr√®s avoir test√© plusieurs mod√®les, le **Random Forest Regressor** s'est av√©r√© le plus performant pour pr√©dire la consommation √©nerg√©tique. Il offre une excellente capacit√© de g√©n√©ralisation et un faible risque de surapprentissage.
        """)

        st.markdown("<h3 style='color: #B19CD9;'>Tableau Comparatif des Mod√®les üìä</h3>", unsafe_allow_html=True) # H3 pour sous-section

        st.write("Voici un tableau r√©capitulatif des performances des diff√©rents mod√®les test√©s :")

        # Cr√©ation du DataFrame avec les donn√©es (bas√© sur l'image mais fourni dans le code pr√©c√©dent)
        # Assurez-vous que ces donn√©es sont correctes ou chargez-les si n√©cessaire
        model_data = {
            'Mod√®le': ['Random Forest', 'Decision Tree', 'LassoCV', 'RidgeCV', 'Linear Regression'],
            'MAE (Entra√Ænement)': [2831.117357, 16726.290844, 36726.768638, 18794.077160, 18794.850116],
            'MSE (Entra√Ænement)': [18071859, 516232825, 2269012402, 625388854, 625284276],
            'R¬≤ (Entra√Ænement)': [0.998107, 0.945931, 0.762351, 0.934499, 0.934510],
            'MAE (Test)': [7702.511192, 16873.532846, 35941.477643, 18737.704528, 18733.597936],
            'MSE (Test)': [133642664, 532403034, 2194812149, 618958955, 618619517],
            'R¬≤ (Test)': [0.985936, 0.943973, 0.769033, 0.934865, 0.934901]
        }
        df_models_results = pd.DataFrame(model_data)
        df_models_results = df_models_results.set_index('Mod√®le') # Mettre le nom du mod√®le comme index

        # Fonction pour appliquer le style (surligner Random Forest)
        def highlight_rf(s):
            '''
            Highlights the Random Forest row with a specific background color.
            '''
            # Applique le style si le nom de l'index (Mod√®le) est 'Random Forest'
            return ['background-color: #5533FF; color: white;' if s.name == 'Random Forest' else '' for _ in s]

        # Appliquer le style et formater les nombres pour l'affichage
        # Ajustement du formatage pour correspondre √† l'image (pas de s√©parateur de milliers)
        st.dataframe(
            df_models_results.style.apply(highlight_rf, axis=1).format({
                'MAE (Entra√Ænement)': '{:.6f}',
                'MSE (Entra√Ænement)': '{:.0f}',
                'R¬≤ (Entra√Ænement)': '{:.6f}',
                'MAE (Test)': '{:.6f}',
                'MSE (Test)': '{:.0f}',
                'R¬≤ (Test)': '{:.6f}',
            }).format_index(escape="html"), # Pour s'assurer que l'index s'affiche correctement
            use_container_width=True # Utiliser toute la largeur disponible
        )

        st.markdown("""
        Comme le montre le tableau ci-dessus, le mod√®le **Random Forest** surpasse nettement les autres mod√®les test√©s en termes de R¬≤, de MAE et de MSE, tant sur les donn√©es d‚Äôentra√Ænement que sur les donn√©es de test. Il offre donc la meilleure capacit√© pr√©dictive pour la consommation √©nerg√©tique dans notre cas d‚Äô√©tude.
        """)

        st.markdown("<h3 style='color: #B19CD9;'>Param√®tres du mod√®le ‚öôÔ∏è</h3>", unsafe_allow_html=True)

        st.write("""
        Les hyperparam√®tres suivants ont √©t√© s√©lectionn√©s apr√®s optimisation avec **GridSearchCV** :
        """)

        st.markdown("""
        *   **n_estimators**: 125 üå≥
            > Nombre d'arbres dans la for√™t. Plus il y a d'arbres, plus le mod√®le est performant, mais plus il est lent √† entra√Æner.
        *   **max_depth**: 20 üñäÔ∏è
            > Profondeur maximale de chaque arbre. Une profondeur plus grande permet de capturer des relations plus complexes, mais augmente le risque de surapprentissage.
        *   **min_samples_split**: 2 ‚úÇÔ∏è
            > Nombre minimum d'√©chantillons requis pour diviser un n≈ìud interne. Une valeur plus √©lev√©e permet d'√©viter de cr√©er des divisions trop sp√©cifiques qui pourraient conduire √† du surapprentissage.
        *   **min_samples_leaf**: 1 üå±
            > Nombre minimum d'√©chantillons requis dans un n≈ìud feuille. Une valeur plus √©lev√©e permet d'√©viter de cr√©er des feuilles avec trop peu d'√©chantillons, ce qui pourrait conduire √† du surapprentissage.
        *   **random_state**: 42 üé≤
            > Graine du g√©n√©rateur de nombres al√©atoires. Fixer cette valeur permet de garantir la reproductibilit√© des r√©sultats.
        """)

        st.write("""
        **GridSearchCV** est une technique d'optimisation qui permet de tester diff√©rentes combinaisons d'hyperparam√®tres et de s√©lectionner la meilleure combinaison en fonction d'une m√©trique de performance (par exemple, le R¬≤).
        """)

        st.divider() # Ajoute une ligne de s√©paration visuelle

        st.markdown("<h3 style='color: #B19CD9;'>R√©sultats du Mod√®le Random Forest üéØ</h3>", unsafe_allow_html=True)
        st.write("Voici les r√©sultats obtenus avec le mod√®le Random Forest optimis√©, sur les jeux d'entra√Ænement et de test :")

        # Donn√©es exactes de l'image
        results_data_rf = {
            'M√©trique': ['R¬≤', 'MAE', 'MSE'],
            # Utiliser '.' pour les d√©cimales en Python
            'Entra√Ænement': [0.9976, 2991.7500, 19427856.7000],
            'Test': [0.9853, 7973.9100, 141255891.4400]
        }
        df_rf_results_specific = pd.DataFrame(results_data_rf).set_index('M√©trique')

        # Affichage avec formatage pour correspondre √† l'image de la demande
        # Utilisation de st.dataframe pour un rendu tabulaire standard
        # Formatage des nombres pour correspondre √† la pr√©cision de l'image
        # Utilisation de la virgule comme s√©parateur de milliers et du point comme s√©parateur d√©cimal
        st.dataframe(
            df_rf_results_specific.style.format({
                'Entra√Ænement': '{:,.4f}'.format, # Format avec virgule milliers, point d√©cimal, 4 d√©cimales
                'Test': '{:,.4f}'.format
            }),
            use_container_width=True # Adapter √† la largeur
        )

        st.markdown("<h3 style='color: #B19CD9;'>Interpr√©tation des r√©sultats üìä</h3>", unsafe_allow_html=True)
        # Texte exact de l'image avec formatage Markdown
        # Note: MSE values rounded to integer, R2 as percentage, MAE rounded to integer
        st.markdown("""
        Le mod√®le Random Forest offre des performances exceptionnelles, avec un coefficient de d√©termination (R¬≤) de **99.76%** sur le jeu d'entra√Ænement et de **98.53%** sur le jeu de test.
        Les erreurs absolues moyennes (MAE) sont de **2992 MW** et **7974 MW** respectivement, et les erreurs quadratiques moyennes (MSE) sont de **19 427 857 MW¬≤** et **141 255 891 MW¬≤**.
        Ces r√©sultats indiquent que le mod√®le est capable de g√©n√©raliser efficacement les donn√©es, tout en minimisant les erreurs de pr√©diction.
        """)

        st.markdown("<h3 style='color: #B19CD9;'>Graphique : Pr√©dictions vs R√©alit√© üìà</h3>", unsafe_allow_html=True)
        st.write("Le graphique suivant compare les pr√©dictions du mod√®le Random Forest aux valeurs r√©elles sur le jeu de test :")

        # --- /!\ AJOUT DE L'IMAGE DEMAND√âE /!\ ---
        if os.path.exists(MODEL_PREDICTION_IMAGE_PATH):
            col_img_left, col_img_center, col_img_right = st.columns([1, 3, 1]) # Ratio pour centrer (colonne centrale plus large)
            with col_img_center:
                st.image(MODEL_PREDICTION_IMAGE_PATH, caption="Pr√©dictions vs R√©alit√© (Mod√®le Optimis√©)")
        else:
            st.warning(f"Image 'Pr√©dictions vs R√©alit√©' non trouv√©e : {MODEL_PREDICTION_IMAGE_PATH}")
            st.info(f"Assurez-vous que le fichier '{os.path.basename(MODEL_PREDICTION_IMAGE_PATH)}' existe dans le dossier '{os.path.dirname(MODEL_PREDICTION_IMAGE_PATH)}'.")
            print(f"Warning: Model prediction image not found: {MODEL_PREDICTION_IMAGE_PATH}") # Log pour console
        # --- /!\ FIN AJOUT DE L'IMAGE /!\ ---

        # --- /!\ AJOUT DE LA CONCLUSION SUR LA MODELISATION /!\ ---
        st.divider() # Ajoute une ligne de s√©paration visuelle avant la conclusion finale

        # Utilise H3 avec la couleur standard des sous-sections ici et ajoute l'emoji ‚úÖ
        st.markdown("<h3 style='color: #B19CD9;'>Conclusion sur la Mod√©lisation ‚úÖ</h3>", unsafe_allow_html=True)
        # Utilise st.markdown pour le texte, permettant le formatage si besoin plus tard
        st.markdown("""
        Le mod√®le Random Forest, avec les hyperparam√®tres optimis√©s, offre d'excellentes performances pour la pr√©diction de la consommation √©nerg√©tique.
        Il pr√©sente une bonne capacit√© de g√©n√©ralisation et une grande pr√©cision. Il surpasse les autres mod√®les test√©s (r√©gression lin√©aire, arbre de d√©cision, Lasso, Ridge).
        """)
        # --- /!\ FIN AJOUT CONCLUSION /!\ ---

# --- /!\ FIN MODIFICATION : La partie Mod√©lisation est maintenant dans l'expander /!\ ---

# --- Section Pr√©diction ---
elif current_choice == "ü§ñ Pr√©diction":
    section_display_name = SECTION_ICONS.get(current_choice, current_choice)
    st.markdown(f"<h1 style='text-align: left;'>{section_display_name}</h1>", unsafe_allow_html=True)
    st.write("Entrez les informations n√©cessaires pour pr√©dire la consommation d'√©lectricit√©, ou ajustez les suggestions de population et d'entreprises avec les curseurs.")
    st.markdown("---") # Ajout d'un s√©parateur

    # --- V√©rification et chargement des artefacts ML ---
    # (Code inchang√© ici - v√©rification pipeline, columns_info, regions_list)
    if pipeline is None or columns_info is None or regions_list is None:
        st.error("‚ùå Erreur critique : Impossible de charger les composants ML n√©cessaires (pipeline, infos colonnes, liste r√©gions).")
        st.warning("V√©rifiez les chemins des fichiers dans la configuration et les logs de d√©marrage pour les erreurs de chargement.")
        st.markdown(f"""
        Chemins des artefacts v√©rifi√©s :
        - Pipeline: `{BEST_PIPELINE_PATH}`
        - Infos Colonnes: `{COLUMNS_INFO_PATH}`
        - R√©gions: `{REGIONS_PATH}`
        """)
        st.stop()

    # --- Chargement des donn√©es contextuelles depuis df_final ---
    # (Code inchang√© ici - chargement et v√©rification de df_final)
    df_final = get_df_final_data()
    if df_final is None:
        st.error(f"‚ùå √âchec critique : Impossible de charger les donn√©es contextuelles depuis df_final.csv ({DF_FINAL_CSV_PATH}).")
        st.warning("La fonctionnalit√© de pr√©diction ne peut pas fournir de valeurs par d√©faut adapt√©es sans ces donn√©es.")
        st.info("V√©rifiez que le fichier existe, qu'il est accessible et n'est pas corrompu.")
        st.stop()
    elif df_final.empty:
        st.warning("‚ö†Ô∏è Le fichier df_final.csv est vide ou n'a pas pu √™tre trait√© correctement. Les valeurs par d√©faut g√©n√©riques seront utilis√©es pour les champs de saisie.")
        context_available = False
        df_final = pd.DataFrame()
    else:
        required_context_cols = ['region', 'date', 'year', 'month', 'population', 'nb_total_entreprise', 'tmoy_degc']
        missing_context_cols = [col for col in required_context_cols if col not in df_final.columns]
        if missing_context_cols:
            st.warning(f"‚ö†Ô∏è Colonnes manquantes dans df_final pour le contexte : {', '.join(missing_context_cols)}. Les valeurs par d√©faut g√©n√©riques seront utilis√©es.")
            context_available = False
        else:
            context_available = True
            try:
                if not pd.api.types.is_datetime64_any_dtype(df_final['date']):
                     df_final['date'] = pd.to_datetime(df_final['date'], errors='coerce')
                for col in ['population', 'nb_total_entreprise', 'tmoy_degc', 'year', 'month']:
                     if col in df_final.columns and not pd.api.types.is_numeric_dtype(df_final[col]):
                         df_final[col] = pd.to_numeric(df_final[col], errors='coerce')
                df_final.dropna(subset=['date', 'region', 'year', 'month'], inplace=True)
                if df_final.empty:
                     st.warning("‚ö†Ô∏è df_final est devenu vide apr√®s nettoyage/conversion des types. Utilisation des valeurs par d√©faut g√©n√©riques.")
                     context_available = False
            except Exception as e_conv:
                 st.warning(f"‚ö†Ô∏è Erreur lors de la v√©rification/conversion des types dans df_final : {e_conv}. Utilisation des valeurs par d√©faut g√©n√©riques.")
                 context_available = False

    # --- Formulaire pour les entr√©es utilisateur ---
    st.subheader("üìù Param√®tres d'entr√©e")
    col1, col2 = st.columns(2)

    with col1:
        # (Widgets R√©gion et Date inchang√©s)
        selected_region = st.selectbox(
            "üìç R√©gion :", options=regions_list, index=0, key="pred_region",
            help="Choisissez la r√©gion pour laquelle vous souhaitez faire une pr√©diction."
        )
        today = datetime.date.today()
        min_hist_date = df_final['date'].min().date() if context_available and not df_final.empty and 'date' in df_final.columns and not df_final['date'].isnull().all() else datetime.date(2019, 1, 1)
        max_pred_date = today + datetime.timedelta(days=730)
        selected_date = st.date_input(
            "üóìÔ∏è Date :", value=today, min_value=min_hist_date, max_value=max_pred_date, key="pred_date",
            help="Choisissez la date pour laquelle vous souhaitez faire une pr√©diction."
        )
        selected_month = selected_date.month
        selected_year = selected_date.year

        # Mettre la temp√©rature ici aussi pour √©quilibrer les colonnes
        st.markdown("<br>", unsafe_allow_html=True) # Espace visuel
        temp_moyenne = st.number_input(
            "üå°Ô∏è Temp√©rature Moyenne (¬∞C) :",
            min_value=-20.0, max_value=45.0,
            value=15.0, # Garder une valeur par d√©faut simple ici, le contexte est calcul√© plus tard
            step=0.1, format="%.1f",
            key="pred_temp",
            help="Temp√©rature moyenne pr√©vue pour la journ√©e."
        )


    # --- Calcul des valeurs sugg√©r√©es (base pour les sliders) ---
    default_pop = 5000000 # Fallback
    default_companies = 300000 # Fallback
    context_pop = "Contexte non disponible"
    context_companies = "Contexte non disponible"
    # (La logique de calcul de default_pop, default_companies, context_pop, context_companies reste la m√™me qu'avant)
    if context_available:
        df_region = df_final.loc[df_final['region'] == selected_region].copy()
        if not df_region.empty:
            min_year_data = int(df_region['year'].min())
            max_year_data = int(df_region['year'].max())
            target_year_socioeco = max(min_year_data, min(selected_year, max_year_data))

            # Population
            pop_col = df_region.loc[df_region['year'] == target_year_socioeco, 'population'].dropna()
            if not pop_col.empty and pd.api.types.is_numeric_dtype(pop_col):
                avg_pop = pop_col.mean()
                default_pop = int(round(avg_pop))
                context_pop = f"{avg_pop:,.0f} hab. (Moy. {selected_region} {target_year_socioeco})".replace(",", " ")
            else:
                context_pop = f"Donn√©e Pop. indisponible ({selected_region} {target_year_socioeco})"

            # Entreprises
            comp_col = df_region.loc[df_region['year'] == target_year_socioeco, 'nb_total_entreprise'].dropna()
            if not comp_col.empty and pd.api.types.is_numeric_dtype(comp_col):
                avg_comp = comp_col.mean()
                default_companies = int(round(avg_comp))
                context_companies = f"{avg_comp:,.0f} entr. (Moy. {selected_region} {target_year_socioeco})".replace(",", " ")
            else:
                context_companies = f"Donn√©e Entr. indisponible ({selected_region} {target_year_socioeco})"
        else:
             context_pop = f"Donn√©es contextuelles indisponibles pour {selected_region}"
             context_companies = context_pop


    # --- Affichage et Sliders pour Population et Entreprises ---
    with col2:
        st.markdown("üë• **Population (habitants)**")
        # Afficher la suggestion
        if context_available and not context_pop.startswith("Contexte non disponible") and not context_pop.startswith("Donn√©e"):
            st.caption(f"‚ÑπÔ∏è Suggestion historique : {context_pop}")
        else:
             st.caption(f"‚ÑπÔ∏è Suggestion historique : {default_pop:,.0f} (valeur g√©n√©rique)".replace(",", " "))

        # Slider pour ajustement en %
        pop_growth_percentage = st.slider(
            "Ajustement Croissance Pop. (%) :",
            min_value=-20.0,  # Permet une baisse de 10%
            max_value=20.0,   # MODIFI√â: Permet une hausse de 10% max
            value=0.0,        # D√©faut √† 0% (pas d'ajustement)
            step=5.0,         # Pas de 0.5%
            format="%.1f%%",  # Affichage avec '%'
            key="pop_growth_slider",
            help=f"Ajustez la croissance par rapport √† la suggestion bas√©e sur l'historique ({context_pop if context_available else 'N/A'})."
        )
        # Calculer la valeur finale
        final_population = float(default_pop) * (1 + pop_growth_percentage / 100.0)
        final_population = int(round(final_population)) # Arrondir √† l'entier le plus proche

        # Afficher la valeur finale utilis√©e (avec s√©parateur)
        st.markdown(f"‚Ü≥ **Population finale estim√©e :** `{final_population:,.0f}`".replace(",", " "))

        st.markdown("---") # S√©parateur visuel

        st.markdown("üè¢ **Nombre Total d'Entreprises**")
        # Afficher la suggestion
        if context_available and not context_companies.startswith("Contexte non disponible") and not context_companies.startswith("Donn√©e"):
            st.caption(f"‚ÑπÔ∏è Suggestion historique : {context_companies}")
        else:
            st.caption(f"‚ÑπÔ∏è Suggestion historique : {default_companies:,.0f} (valeur g√©n√©rique)".replace(",", " "))

        # Slider pour ajustement en %
        company_growth_percentage = st.slider(
            "Ajustement Croissance Entr. (%) :",
            min_value=-20.0,  # Permet une baisse de 10%
            max_value=20.0,   # MODIFI√â: Permet une hausse de 10% max
            value=0.0,        # D√©faut √† 0%
            step=5.0,         # Pas de 0.5%
            format="%.1f%%",  # Affichage avec '%'
            key="company_growth_slider",
            help=f"Ajustez la croissance par rapport √† la suggestion bas√©e sur l'historique ({context_companies if context_available else 'N/A'})."
        )
        # Calculer la valeur finale
        final_companies = float(default_companies) * (1 + company_growth_percentage / 100.0)
        final_companies = int(round(final_companies))

        # Afficher la valeur finale utilis√©e (avec s√©parateur)
        st.markdown(f"‚Ü≥ **Nombre final d'entreprises :** `{final_companies:,.0f}`".replace(",", " "))


    # --- Bouton de Pr√©diction et Logique Associ√©e ---
    st.markdown("---")
    if st.button("üîÆ Lancer la Pr√©diction", key="predict_button", type="primary", use_container_width=True):

        # 1. Pr√©parer le DataFrame d'entr√©e pour le mod√®le
        try:
            selected_datetime = datetime.datetime.combine(selected_date, datetime.datetime.min.time())

            # Extraire les features temporelles
            date_features = {
                'year': selected_datetime.year,
                'month': selected_datetime.month,
                'day': selected_datetime.day,
                'dayofweek': selected_datetime.weekday(),
                'dayofyear': selected_datetime.timetuple().tm_yday,
                'weekofyear': selected_datetime.isocalendar().week,
                'quarter': (selected_datetime.month - 1) // 3 + 1
            }

            # Construire le dictionnaire avec les donn√©es d'entr√©e
            # Utilise temp_moyenne du widget et les valeurs FINALES calcul√©es par les sliders
            input_data = {
                'region': selected_region,
                'tmoy_degc': temp_moyenne,       # Valeur du widget temp√©rature
                'population': float(final_population), # VALEUR FINALE du slider pop
                'nb_total_entreprise': float(final_companies), # VALEUR FINALE du slider entr
                **date_features
            }

            input_df = pd.DataFrame([input_data])

            # 2. S'assurer de l'ordre et de l'existence des colonnes
            if columns_info and 'original_features' in columns_info:
                expected_columns = columns_info['original_features']
            else:
                st.error("‚ùå Information cruciale manquante : Liste des 'original_features' non trouv√©e dans 'columns_info.json'.")
                st.stop()

            missing_cols_in_input = [col for col in expected_columns if col not in input_df.columns]
            if missing_cols_in_input:
                st.error(f"‚ùå Erreur interne : Colonnes manquantes lors de la cr√©ation de l'entr√©e : {', '.join(missing_cols_in_input)}")
                st.stop()

            try:
                input_df_ordered = input_df[expected_columns]
            except KeyError as e:
                st.error(f"‚ùå Erreur lors de la r√©organisation des colonnes : {e}.")
                st.stop()

            # 3. Faire la pr√©diction
            with st.spinner("üß† Calcul de la pr√©diction en cours..."):
                prediction = pipeline.predict(input_df_ordered)

            # 4. Afficher le r√©sultat
            predicted_value = prediction[0]
            st.markdown("---")
            st.subheader("‚úÖ R√©sultat de la Pr√©diction")
            st.metric(
                label=f"Consommation √âlectrique Pr√©dite pour {selected_region} le {selected_date.strftime('%d/%m/%Y')}",
                value=f"{predicted_value:,.2f} MW".replace(",", " "),
            )
            # Afficher un r√©sum√© des param√®tres utilis√©s pour la pr√©diction
            st.markdown("Avec les param√®tres finaux suivants :")
            st.markdown(f"- Temp√©rature : `{temp_moyenne:.1f}¬∞C`")
            st.markdown(f"- Population : `{final_population:,.0f}` (ajustement `{pop_growth_percentage:.1f}%`)".replace(',',' '))
            st.markdown(f"- Entreprises : `{final_companies:,.0f}` (ajustement `{company_growth_percentage:.1f}%`)".replace(',',' '))

            st.success("Pr√©diction calcul√©e avec succ√®s !")

        # (Gestion des erreurs inchang√©e)
        except FileNotFoundError as fnf_error:
            st.error(f"‚ùå Erreur de Fichier Non Trouv√© : {fnf_error}")
        except KeyError as key_error:
            st.error(f"‚ùå Erreur de Cl√© (colonne manquante ?) : {key_error}")
            # ... (messages de debug potentiels)
        except ValueError as val_error:
             st.error(f"‚ùå Erreur de Valeur : {val_error}")
             # ... (messages de debug potentiels)
        except Exception as e:
            st.error(f"‚ùå Une erreur inattendue est survenue lors du processus de pr√©diction.")
            st.exception(e)
            st.info("Veuillez v√©rifier les logs de la console pour plus de d√©tails.")
            # ... (messages de debug potentiels)


# --- Section Conclusion ---
elif current_choice == "üìå Conclusion":
    section_display_name = SECTION_ICONS.get(current_choice, current_choice)
    st.markdown(f"<h1 style='text-align: left;'>{section_display_name}</h1>", unsafe_allow_html=True)

    # --- Introduction de la Conclusion (existante) ---
    st.markdown("""
    Ce projet a permis d'explorer les dynamiques de consommation √©nerg√©tique en France et d'√©tablir des mod√®les pr√©dictifs performants pour anticiper la demande √©nerg√©tique. √Ä travers des analyses approfondies des donn√©es historiques, nous avons identifi√© les facteurs cl√©s influen√ßant la consommation √©lectrique, notamment les variations climatiques et les tendances d√©mographiques.
    """)

    # --- R√©sultats Cl√©s (existants) ---
    st.markdown("### üåü R√©sultats cl√©s :")
    st.markdown("""
    *   **Exploration des donn√©es :**
        *   Identification des variations saisonni√®res de la consommation √©nerg√©tique.
        *   Analyse des contributions des diff√©rentes sources d'√©nergie (nucl√©aire, renouvelables, etc.).
    *   **Mod√©lisation et Pr√©dictions :**
        *   Utilisation du mod√®le Random Forest pour pr√©dire la consommation √©nerg√©tique r√©gionale avec un **R¬≤ de 98,5%** sur les donn√©es de test.
        *   Int√©gration de variables cl√©s comme la temp√©rature moyenne, la population et la r√©gion pour des pr√©dictions pr√©cises.
    """)


    # --- /!\ AJOUT DU CONTENU DE L'IMAGE ICI /!\ ---

    # --- Points d'am√©lioration (depuis l'image) ---
    st.markdown("### üîë Points d'am√©lioration :") # Utilisation de l'emoji cl√©
    st.markdown("""
    *   **Int√©gration de nouvelles donn√©es :**
        *   Ajouter des variables comme les jours f√©ri√©s, les vagues de froid/chaleur ou les √©v√©nements √©conomiques pour affiner les pr√©dictions.
    *   **Adoption de mod√®les avanc√©s :**
        *   Tester des mod√®les complexes tels que les r√©seaux neuronaux pour mieux capturer les non-lin√©arit√©s dans les donn√©es.
    """)


    # --- Contribution pour la transition √©nerg√©tique (depuis l'image) ---
    st.markdown("### üåü Contribution pour la transition √©nerg√©tique :") # Utilisation de l'emoji √©toile
    st.markdown("""
    Ce projet apporte des outils pour mieux comprendre et pr√©voir la consommation √©nerg√©tique, contribuant ainsi √† une gestion plus efficace des ressources.
    """)


    # --- Message final (depuis l'image) ---
    st.markdown( # CORRECTION: Ajout de la parenth√®se fermante ici
        """
        <p style='text-align: center;'>
        üöÄ Merci d'avoir suivi ce projet. Ensemble, avan√ßons vers un futur √©nerg√©tique durable ! üöÄ
        </p>
        """,
        unsafe_allow_html=True
    )

    # --- /!\ FIN DE L'AJOUT DU CONTENU DE L'IMAGE /!\ ---


# =============================================================================
# --- 8. FOOTER --- (PROPOSITION 3 - AVEC SITE WEB)
# =============================================================================

# D√©finir les URLs et autres constantes
linkedin_url = "https://www.linkedin.com/in/jeremy-vanerpe/"
github_url = "https://github.com/JVEdata"
website_url = "https://jeremyvanerpe.fr/"
developer_name = "J√©r√©my VAN ERPE"

# Obtenir l'ann√©e actuelle dynamiquement
import datetime
current_year = datetime.date.today().year

# Construire le HTML du footer avec CSS int√©gr√©
footer_html = f"""
<style>
    /* Style pour le conteneur du footer */
    #app-footer-pro {{
        text-align: center;
        padding: 1.5em 0;
        margin-top: 3em;
        font-size: 0.9em;
        color: #CCCCCC;
        border-top: 1px solid #333333;
    }}

    /* Style pour les liens */
    #app-footer-pro a {{
        color: #A0DAFF;
        text-decoration: none;
        transition: color 0.2s ease;
    }}

    /* Style des liens au survol */
    #app-footer-pro a:hover {{
        color: #FFFFFF;
    }}

    /* Style pour les s√©parateurs */
    #app-footer-pro .separator {{
        margin: 0 0.7em;
        color: #555555;
    }}

    /* Style pour les ic√¥nes/emojis */
    #app-footer-pro .icon {{
        display: inline-block;
        margin-right: 0.35em;
        font-size: 1.1em;
        vertical-align: -0.1em;
    }}
</style>

<div id="app-footer-pro">
    <span>¬© {current_year} {developer_name}</span>
    <span class="separator">|</span>
    <span>D√©velopp√© avec
        <span class="icon" role="img" aria-label="√âclair">‚ö°</span>Streamlit &
        <span class="icon" role="img" aria-label="Panda">üêº</span>Pandas
    </span>
    <span class="separator">|</span>
    <a href="{website_url}" target="_blank" rel="noopener noreferrer">
        <span class="icon" role="img" aria-label="Globe">üåê</span>Site Web
    </a>
    <span class="separator">|</span>
    <a href="{linkedin_url}" target="_blank" rel="noopener noreferrer">
        <span class="icon" role="img" aria-label="Lien">üíº</span>LinkedIn
    </a>
    <span class="separator">|</span>
    <a href="{github_url}" target="_blank" rel="noopener noreferrer">
        <span class="icon" role="img" aria-label="Octopus GitHub">üêô</span>GitHub
    </a>
</div>
"""

# Assurez-vous que la biblioth√®que streamlit est import√©e
#import streamlit as st # D√©j√† import√© plus haut

# Afficher le footer en tant que HTML
st.markdown(footer_html, unsafe_allow_html=True)